{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Shelter (XGBoost+k-NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Animal Shelter dataset and display a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalID</th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A671945</td>\n",
       "      <td>Hambone</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A656520</td>\n",
       "      <td>Emily</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>Suffering</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Cream Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A686464</td>\n",
       "      <td>Pearce</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>Blue/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A683430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-07-11 19:09:00</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Blue Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A667013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-15 12:52:00</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "      <td>Tan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AnimalID     Name             DateTime      OutcomeType OutcomeSubtype  \\\n",
       "0  A671945  Hambone  2014-02-12 18:22:00  Return_to_owner            NaN   \n",
       "1  A656520    Emily  2013-10-13 12:44:00       Euthanasia      Suffering   \n",
       "2  A686464   Pearce  2015-01-31 12:28:00         Adoption         Foster   \n",
       "3  A683430      NaN  2014-07-11 19:09:00         Transfer        Partner   \n",
       "4  A667013      NaN  2013-11-15 12:52:00         Transfer        Partner   \n",
       "\n",
       "  AnimalType SexuponOutcome AgeuponOutcome                        Breed  \\\n",
       "0        Dog  Neutered Male         1 year        Shetland Sheepdog Mix   \n",
       "1        Cat  Spayed Female         1 year       Domestic Shorthair Mix   \n",
       "2        Dog  Neutered Male        2 years                 Pit Bull Mix   \n",
       "3        Cat    Intact Male        3 weeks       Domestic Shorthair Mix   \n",
       "4        Dog  Neutered Male        2 years  Lhasa Apso/Miniature Poodle   \n",
       "\n",
       "         Color  \n",
       "0  Brown/White  \n",
       "1  Cream Tabby  \n",
       "2   Blue/White  \n",
       "3   Blue Cream  \n",
       "4          Tan  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalID</th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26729</td>\n",
       "      <td>19038</td>\n",
       "      <td>26729</td>\n",
       "      <td>26729</td>\n",
       "      <td>13117</td>\n",
       "      <td>26729</td>\n",
       "      <td>26728</td>\n",
       "      <td>26711</td>\n",
       "      <td>26729</td>\n",
       "      <td>26729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>26729</td>\n",
       "      <td>6374</td>\n",
       "      <td>22918</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>1380</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A705677</td>\n",
       "      <td>Max</td>\n",
       "      <td>2015-08-11 00:00:00</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Black/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>19</td>\n",
       "      <td>10769</td>\n",
       "      <td>7816</td>\n",
       "      <td>15595</td>\n",
       "      <td>9779</td>\n",
       "      <td>3969</td>\n",
       "      <td>8810</td>\n",
       "      <td>2824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AnimalID   Name             DateTime OutcomeType OutcomeSubtype  \\\n",
       "count     26729  19038                26729       26729          13117   \n",
       "unique    26729   6374                22918           5             16   \n",
       "top     A705677    Max  2015-08-11 00:00:00    Adoption        Partner   \n",
       "freq          1    136                   19       10769           7816   \n",
       "\n",
       "       AnimalType SexuponOutcome AgeuponOutcome                   Breed  \\\n",
       "count       26729          26728          26711                   26729   \n",
       "unique          2              5             44                    1380   \n",
       "top           Dog  Neutered Male         1 year  Domestic Shorthair Mix   \n",
       "freq        15595           9779           3969                    8810   \n",
       "\n",
       "              Color  \n",
       "count         26729  \n",
       "unique          366  \n",
       "top     Black/White  \n",
       "freq           2824  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n",
      "(26729, 10)\n",
      "(21383, 10)\n",
      "      AnimalID    Name             DateTime OutcomeType OutcomeSubtype  \\\n",
      "12647  A710476     NaN  2015-08-25 15:18:00    Transfer        Partner   \n",
      "16303  A703907    Fawn  2015-06-08 16:25:00    Transfer        Partner   \n",
      "3792   A700136     NaN  2015-04-18 14:22:00        Died      In Foster   \n",
      "13021  A664073  Parker  2013-10-07 17:06:00    Adoption            NaN   \n",
      "4295   A716795     NaN  2015-11-29 08:57:00  Euthanasia    Rabies Risk   \n",
      "\n",
      "      AnimalType SexuponOutcome AgeuponOutcome                   Breed  \\\n",
      "12647        Cat    Intact Male        1 month  Domestic Shorthair Mix   \n",
      "16303        Cat    Intact Male        4 weeks  Domestic Shorthair Mix   \n",
      "3792         Cat    Intact Male        4 weeks  Domestic Shorthair Mix   \n",
      "13021        Dog  Neutered Male        2 years            Hovawart Mix   \n",
      "4295         Cat        Unknown       2 months  Domestic Shorthair Mix   \n",
      "\n",
      "                      Color  \n",
      "12647          Orange Tabby  \n",
      "16303                 Black  \n",
      "3792            Brown Tabby  \n",
      "13021             Black/Tan  \n",
      "4295   Orange Tabby/Apricot  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "print sklearn.__version__\n",
    "# Split the dataset into Train/Test\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(df, df[[\"OutcomeType\"]], test_size=0.2, random_state=42, stratify=df[[\"OutcomeType\"]])\n",
    "\n",
    "print df.shape\n",
    "print X_train_df.shape\n",
    "print X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data  Preparation\n",
    "\n",
    "\n",
    "Split the \"SexuponOutcome\" field into \"Sex\" and \"Neutered\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitSex(df):\n",
    "    print \"splitSex...\"\n",
    "    df.loc[df[\"SexuponOutcome\"].isnull(), \"SexuponOutcome\"]=\"unknown\"\n",
    "\n",
    "    df[\"Sex\"] = df[\"SexuponOutcome\"].str.lower().str.contains(\" male\")\n",
    "    df.loc[df[\"SexuponOutcome\"].str.lower().str.contains(\" male\"), \"Sex\"] = \"male\"\n",
    "    df.loc[df[\"SexuponOutcome\"].str.lower().str.contains(\"female\"), \"Sex\"] = \"female\"\n",
    "    df.loc[df[\"SexuponOutcome\"].str.lower().str.contains(\"unknown\"), \"Sex\"] = \"unknown\"\n",
    "\n",
    "    df[\"Neutered\"] = (df[\"SexuponOutcome\"].str.lower().str.contains(\"neutered\")) |  (df[\"SexuponOutcome\"].str.lower().str.contains(\"spayed\"))\n",
    "    df[\"Neutered\"] = df[\"Neutered\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processName(df):\n",
    "    print \"processName...\"\n",
    "    \n",
    "    df[\"HasName\"] = ~df[\"Name\"].isnull()\n",
    "    df[\"HasName\"] = df[\"HasName\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the breed field. Here we determine if an animal is a purebreed or a mix and create a new field encoding this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleanupBreed...\n"
     ]
    }
   ],
   "source": [
    "def cleanupBreed(df):\n",
    "    print \"cleanupBreed...\"\n",
    "    \n",
    "    df[\"PureBreed\"] = ~df[\"Breed\"].str.lower().str.contains(\"mix\")\n",
    "    df.loc[df[\"Breed\"].str.contains(\"/\"), \"PureBreed\"]=False\n",
    "    df[\"PureBreed\"] = df[\"PureBreed\"].astype(int)\n",
    "    df[[\"Breed\", \"PureBreed\"]].head(10)\n",
    "    \n",
    "cleanupBreed(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dog breed potentially encodes information that could improve classifier predictions, such as size of dog, breed popularity, breed temperament and longevity etc. This information, however is difficult to extract from the breed. Instead we encode the breed field into a set of features that can then be used by the classifier. The breed field is transformed into features by calculating a term-document matrix taking the rows in the Breed column as the document corpus. This results in the breed words being vectorized. \n",
    "\n",
    "This should allow the classifier to implicitly infer information regarding the breeds which affects the outcome. For example if chihuahuas or chihuahua mixes are unpopular for adoption, any breed mentioning chihuahua should result in a lower probability of adoption in the classifier. If medium sized breeds tend to be adopted more frequently, this should also be a correlation that emerges in the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "breedsVec = CountVectorizer()\n",
    "pca = PCA()\n",
    "\n",
    "def fitPCA(df):\n",
    "    print \"fitPCA...\"\n",
    "    breedsTDM = breedsVec.transform(df[\"Breed\"])\n",
    "    pca.fit(breedsTDM.toarray())\n",
    "    \n",
    "def preprocessBreed(df):\n",
    "    print \"preprocessBreed...\"\n",
    "    #vec = CountVectorizer()\n",
    "    \n",
    "    breedsVec.fit(df[\"Breed\"])#.str.replace(\"Mix\", \"\").str.replace(\"/\", \" \").str.lower())\n",
    "    \n",
    "    fitPCA(df)\n",
    "    \n",
    "    return breedsVec\n",
    "\n",
    "def processBreed(df, doPCA=0):\n",
    "    print \"processBreed...\"\n",
    "    \n",
    "    breedsTDM = breedsVec.transform(df[\"Breed\"])#.str.replace(\"Mix\", \"\").str.replace(\"/\", \" \").str.lower())\n",
    "    print breedsTDM.toarray().shape\n",
    "    \n",
    "    if doPCA>0 :\n",
    "\n",
    "        cumul_variance = [sum(pca.explained_variance_ratio_[:i]) for i in range(len(pca.explained_variance_ratio_))]\n",
    "        print sum(pca.explained_variance_ratio_[:3])\n",
    "       # print pca.explained_variance_ratio_\n",
    "        #print cumul_variance\n",
    "\n",
    "        numDims = len(cumul_variance)\n",
    "        for i in range(len(cumul_variance)):\n",
    "            if cumul_variance[i]>=doPCA:\n",
    "                numDims = i\n",
    "                break\n",
    "\n",
    "        print \"NumDims=\", numDims\n",
    "\n",
    "        reduced_dims = pca.transform(breedsTDM.toarray())\n",
    "        reduced_dims = reduced_dims[:,:numDims]\n",
    "\n",
    "        print reduced_dims.shape\n",
    "        breedsdf = pd.DataFrame(reduced_dims)#breedsTDM.toarray())\n",
    "        breedCols = [\"Breed_\"+str(i) for i in range(0, reduced_dims.shape[1]) ]\n",
    "        breedsdf.columns = breedCols\n",
    "        #print breedsdf.head()\n",
    "\n",
    "        df = df.join(breedsdf)\n",
    "    else:\n",
    "        breedsdf = pd.DataFrame(breedsTDM.toarray())\n",
    "        breedCols = [\"Breed_\"+breedsVec.get_feature_names()[i] for i in range(0, breedsTDM.shape[1]) ]\n",
    "        breedsdf.columns = breedCols\n",
    "        #print breedsdf.head()\n",
    "\n",
    "        df = df.join(breedsdf)\n",
    "\n",
    "    \n",
    "    #print df.head()\n",
    "    return df\n",
    "\n",
    "\n",
    "#preprocessBreed(df)\n",
    "#df = processBreed(df, False)\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that translates the age fields in the dataset to days by parsing the units (year(s), month(s), week(s)). We then map the age in days to an ageBracket field so as to categories the animals as (BABY, JUVENILE, ADULT, SENIOR). Animal shelters do not allow animals to be adopted before they are weaned, therefore the \"BABY\" bracket should add resultion to our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAgeInDays(ageStr):\n",
    "    if pd.isnull(ageStr):\n",
    "        return ageStr\n",
    "    \n",
    "    ageParts = ageStr.lower().split(\" \")\n",
    "    val = int(ageParts[0])\n",
    "    units = ageParts[1]\n",
    "    \n",
    "    if units[-1:]==\"s\":\n",
    "        units = units[0:-1]\n",
    "    \n",
    "    if units==\"year\":\n",
    "        val = 365*val\n",
    "    elif units==\"month\":\n",
    "        val = 30*val\n",
    "    elif units==\"week\":\n",
    "        val = 7*val\n",
    "    \n",
    "    return val\n",
    "\n",
    "def getAgeBracket(ageInDays):\n",
    "    if ageInDays<=42:\n",
    "        return \"baby\"\n",
    "    elif ageInDays<=365:\n",
    "        return \"juvenile\"\n",
    "    elif ageInDays<=365*9:\n",
    "        return \"adult\"\n",
    "    else:\n",
    "        return \"senior\"\n",
    "\n",
    "    \n",
    "def processAge(df):\n",
    "    print \"processAge...\"\n",
    "    \n",
    "    df[\"AgeDays\"] = df[\"AgeuponOutcome\"].apply(getAgeInDays)\n",
    "    meanAge = df[[\"AgeDays\"]].mean()\n",
    "\n",
    "    df.loc[df[\"AgeDays\"].isnull(), \"AgeDays\"]=meanAge[0]\n",
    "    df[\"AgeBracket\"] = df[\"AgeDays\"].apply(getAgeBracket)\n",
    "    \n",
    "    \n",
    "#processAge(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we also take the DateTime column and we split the day into 3 hour segments. This should tell us the most likely time of day for an outcome. It looks like most adoptions as well as most transfers occur during the afternoon and early evening, peaking around 17:00 (unsurprising as it is the time most people finish their dayjob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsToDaySegment(ts):\n",
    "    return \"HR_\"+str(int(ts.hour/3))\n",
    "    \n",
    "def processDate(df):\n",
    "    print \"processDate...\"\n",
    "    \n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    df[\"DaySegment\"] = df[\"DateTime\"].apply(tsToDaySegment)\n",
    "    df[\"OutcomeDay\"] = df[\"DateTime\"].dt.day\n",
    "    df[\"OutcomeMonth\"] = df[\"DateTime\"].dt.month\n",
    "    df[\"OutcomeHour\"] = df[\"DateTime\"].dt.hour\n",
    "    \n",
    "#processDate(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an \"IsWeekend\" feature to hopefully help the classifier along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processWeekend(df):\n",
    "    print \"processWeekend...\"\n",
    "    \n",
    "    df[\"IsWeekend\"] = df[\"DateTime\"].apply(lambda ts: (ts.weekday()>=5))\n",
    "    df[\"IsWeekend\"] = df[\"IsWeekend\"].astype(int)\n",
    "\n",
    "#processWeekend(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does having a name make a difference to the outcome? Yes. Having a name is much more likely to result in adoption and/or return to owner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processName(df):\n",
    "    print \"processName...\"\n",
    "    \n",
    "    df[\"HasName\"] = ~df[\"Name\"].isnull()\n",
    "    df[\"HasName\"] = df[\"HasName\"].astype(int)\n",
    "\n",
    "\n",
    "#processName(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to simplify the color field. There are too many unique colors. We do this by splitting on \"/\" or \" \" and taking only the first word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[\"SimpleColor\"] = df[\"Color\"].apply(lambda c: c.split(\"/| \")[0])\n",
    "def processColor(df):\n",
    "    print \"processColor...\"\n",
    "    \n",
    "    df[\"SimpleColor\"] = df[\"Color\"].apply(lambda c: c.lower().split(\"/\")[0].split(\" \")[0])\n",
    "\n",
    "\n",
    "#processColor(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Need to install sklearn_pandas for DataFrameMapper. This is more flexible than sklearn pipeline\n",
    "# because it can perform separate operations on different columns of the dataframe.\n",
    "# pip install sklearn-pandas\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "     (\"AnimalType\", preprocessing.LabelBinarizer()),\n",
    "     (\"Sex\", preprocessing.LabelBinarizer()),\n",
    "     (\"Neutered\", preprocessing.LabelBinarizer()),\n",
    "     (\"PureBreed\", preprocessing.LabelBinarizer()),\n",
    "     (\"AgeBracket\", preprocessing.LabelBinarizer()),\n",
    "     (\"DaySegment\", preprocessing.LabelBinarizer()),\n",
    "     (\"IsWeekend\", preprocessing.LabelBinarizer()),\n",
    "     (\"HasName\", preprocessing.LabelBinarizer()),\n",
    "     (\"SimpleColor\", None),\n",
    "], default=None, df_out=True)\n",
    "\n",
    "labelMapper = DataFrameMapper([\n",
    "    (\"OutcomeType\", preprocessing.LabelEncoder()),\n",
    "], df_out=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareDFForPrediction(df_x, df_y=None, doPCA=False):\n",
    "    df_x_c = df_x.copy()\n",
    "    \n",
    "    splitSex(df_x_c)\n",
    "    cleanupBreed(df_x_c)\n",
    "    df_x_c = processBreed(df_x_c, doPCA) \n",
    "    processAge(df_x_c)    \n",
    "    processDate(df_x_c)\n",
    "    processWeekend(df_x_c)\n",
    "    processName(df_x_c)\n",
    "    processColor(df_x_c)\n",
    "    \n",
    "    # Transform the independent features\n",
    "    df_x_c = mapper.fit_transform(df_x_c)\n",
    "    \n",
    "    if df_y is not None:\n",
    "        # Transform the target field\n",
    "        df_y_c = labelMapper.fit_transform(df_y)\n",
    "    else:\n",
    "        df_y_c = None\n",
    "        \n",
    "    df_x_c = df_x_c.drop([\"Name\", \"DateTime\", \"SexuponOutcome\", \"AgeuponOutcome\", \"Breed\", \"Color\", \"Sex_unknown\",  \"AgeBracket_senior\", \"SimpleColor\"], axis=1)\n",
    "\n",
    "    if \"AnimalID\" in df_x_c.columns.values:\n",
    "        df_x_c = df_x_c.drop([\"AnimalID\"], axis=1)\n",
    "        \n",
    "    if \"OutcomeSubtype\" in df_x_c.columns.values:\n",
    "        df_x_c = df_x_c.drop([\"OutcomeSubtype\"], axis=1)\n",
    "        \n",
    "    if \"OutcomeType\" in df_x_c.columns.values:\n",
    "        df_x_c = df_x_c.drop([\"OutcomeType\"], axis=1)     \n",
    "   \n",
    "\n",
    "    df_x_c.fillna(value=0, inplace=True)\n",
    "    \n",
    "    return df_x_c, df_y_c\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How balanced or unbalanced are our classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that there is a severe inbalance in the prediction classes.\n",
    "\n",
    "The simplest solution is to duplicate records in the minority classes, however experiments with this approach resulted in a worse classifier performance.\n",
    "\n",
    "Instead we use SMOTE (further down) which empirically gives much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outcomeCounts = df.pivot_table(index=[\"OutcomeType\"], values=[\"AnimalID\"], aggfunc=len)\n",
    "#\n",
    "#maxOutcomeCount = np.max(outcomeCounts.values.ravel())\n",
    "#\n",
    "#outcomes = df[\"OutcomeType\"].unique()\n",
    "#\n",
    "##newrecords = pd.DataFrame(columns=df.columns)\n",
    "#\n",
    "#newrecords = pd.DataFrame.from_items(\n",
    "#    [(name, pd.Series(data=None, dtype=series.dtype)) for name, series in df.iteritems()])\n",
    "#\n",
    "#for outcome in outcomes:\n",
    "#    outcomeCount = outcomeCounts.loc[outcome].values[0]\n",
    "#    diff = maxOutcomeCount - outcomeCount\n",
    "#    \n",
    "#    if diff > 0:\n",
    "#        subset = pd.DataFrame(df.loc[df[\"OutcomeType\"]==outcome,:])\n",
    "#        subset = subset.iloc[np.random.randint(0, subset.index.size, size=diff)]\n",
    "#        print outcome, \": added \", subset.index.size, \" records\"\n",
    "#        newrecords = newrecords.append(subset)\n",
    "#        \n",
    "#print \"Total records added: \", newrecords.index.size\n",
    "\n",
    "#df = df.append(newrecords)\n",
    "\n",
    "#sns.countplot(data=df, x=\"OutcomeType\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model\n",
    "\n",
    "Prepare the dataset for learning\n",
    "\n",
    "N.B. We will treat OutcomeType as the dependant variable. OutcomeType is directly inferable from OutcomeSubtype, however this goes contrary to the spirit of the Kaggle challenge and the Kaggle testing set does not include this field among the features, therefore in order for our learning algorithm not to be trivial, we will remove this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AnimalID    Name             DateTime OutcomeType OutcomeSubtype  \\\n",
      "12647  A710476     NaN  2015-08-25 15:18:00    Transfer        Partner   \n",
      "16303  A703907    Fawn  2015-06-08 16:25:00    Transfer        Partner   \n",
      "3792   A700136     NaN  2015-04-18 14:22:00        Died      In Foster   \n",
      "13021  A664073  Parker  2013-10-07 17:06:00    Adoption            NaN   \n",
      "4295   A716795     NaN  2015-11-29 08:57:00  Euthanasia    Rabies Risk   \n",
      "\n",
      "      AnimalType SexuponOutcome AgeuponOutcome                   Breed  \\\n",
      "12647        Cat    Intact Male        1 month  Domestic Shorthair Mix   \n",
      "16303        Cat    Intact Male        4 weeks  Domestic Shorthair Mix   \n",
      "3792         Cat    Intact Male        4 weeks  Domestic Shorthair Mix   \n",
      "13021        Dog  Neutered Male        2 years            Hovawart Mix   \n",
      "4295         Cat        Unknown       2 months  Domestic Shorthair Mix   \n",
      "\n",
      "                      Color  \n",
      "12647          Orange Tabby  \n",
      "16303                 Black  \n",
      "3792            Brown Tabby  \n",
      "13021             Black/Tan  \n",
      "4295   Orange Tabby/Apricot  \n",
      "preprocessBreed...\n",
      "fitPCA...\n",
      "splitSex...\n",
      "cleanupBreed...\n",
      "processBreed...\n",
      "(21383, 262)\n",
      "processAge...\n",
      "processDate...\n",
      "processWeekend...\n",
      "processName...\n",
      "processColor...\n",
      "splitSex...\n",
      "cleanupBreed...\n",
      "processBreed...\n",
      "(5346, 262)\n",
      "processAge...\n",
      "processDate...\n",
      "processWeekend...\n",
      "processName...\n",
      "processColor...\n",
      "       AnimalType  Sex_female  Sex_male  Neutered  PureBreed  \\\n",
      "12647           0           0         1         0          0   \n",
      "16303           0           0         1         0          0   \n",
      "3792            0           0         1         0          0   \n",
      "13021           1           0         1         1          0   \n",
      "4295            0           0         0         0          0   \n",
      "\n",
      "       AgeBracket_adult  AgeBracket_baby  AgeBracket_juvenile  \\\n",
      "12647                 0                1                    0   \n",
      "16303                 0                1                    0   \n",
      "3792                  0                1                    0   \n",
      "13021                 1                0                    0   \n",
      "4295                  0                0                    1   \n",
      "\n",
      "       DaySegment_HR_0  DaySegment_HR_1     ...       Breed_whippet  \\\n",
      "12647                0                0     ...                 0.0   \n",
      "16303                0                0     ...                 0.0   \n",
      "3792                 0                0     ...                 0.0   \n",
      "13021                0                0     ...                 0.0   \n",
      "4295                 0                0     ...                 0.0   \n",
      "\n",
      "       Breed_wire  Breed_wirehair  Breed_wirehaired  Breed_wolfhound  \\\n",
      "12647         0.0             0.0               0.0              0.0   \n",
      "16303         0.0             0.0               0.0              0.0   \n",
      "3792          0.0             0.0               0.0              0.0   \n",
      "13021         0.0             0.0               0.0              0.0   \n",
      "4295          0.0             0.0               0.0              0.0   \n",
      "\n",
      "       Breed_yorkshire  AgeDays  OutcomeDay  OutcomeMonth  OutcomeHour  \n",
      "12647              0.0     30.0          25             8           15  \n",
      "16303              0.0     28.0           8             6           16  \n",
      "3792               0.0     28.0          18             4           14  \n",
      "13021              0.0    730.0           7            10           17  \n",
      "4295               0.0     60.0          29            11            8  \n",
      "\n",
      "[5 rows x 284 columns]\n"
     ]
    }
   ],
   "source": [
    "print X_train_df.head()\n",
    "preprocessBreed(df)\n",
    "X_train_df, y_train_df = prepareDFForPrediction(X_train_df, y_train_df, doPCA=0)\n",
    "X_test_df, y_test_df = prepareDFForPrediction(X_test_df, y_test_df, doPCA=0)\n",
    "print X_train_df.head()\n",
    "\n",
    "X_train = X_train_df.values\n",
    "y_train = y_train_df.values\n",
    "\n",
    "X_test = X_test_df.values\n",
    "y_test = y_test_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How balanced or unbalanced are our classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model\n",
    "\n",
    "Prepare the dataset for learning\n",
    "\n",
    "N.B. We will treat OutcomeType as the dependant variable. OutcomeType is directly inferable from OutcomeSubtype, however this goes contrary to the spirit of the Kaggle challenge and the Kaggle testing set does not include this field among the features, therefore in order for our learning algorithm not to be trivial, we will remove this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalID</th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>PureBreed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A671945</td>\n",
       "      <td>Hambone</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A656520</td>\n",
       "      <td>Emily</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>Suffering</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Cream Tabby</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A686464</td>\n",
       "      <td>Pearce</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>Blue/White</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A683430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-07-11 19:09:00</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Blue Cream</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A667013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-15 12:52:00</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "      <td>Tan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AnimalID     Name             DateTime      OutcomeType OutcomeSubtype  \\\n",
       "0  A671945  Hambone  2014-02-12 18:22:00  Return_to_owner            NaN   \n",
       "1  A656520    Emily  2013-10-13 12:44:00       Euthanasia      Suffering   \n",
       "2  A686464   Pearce  2015-01-31 12:28:00         Adoption         Foster   \n",
       "3  A683430      NaN  2014-07-11 19:09:00         Transfer        Partner   \n",
       "4  A667013      NaN  2013-11-15 12:52:00         Transfer        Partner   \n",
       "\n",
       "  AnimalType SexuponOutcome AgeuponOutcome                        Breed  \\\n",
       "0        Dog  Neutered Male         1 year        Shetland Sheepdog Mix   \n",
       "1        Cat  Spayed Female         1 year       Domestic Shorthair Mix   \n",
       "2        Dog  Neutered Male        2 years                 Pit Bull Mix   \n",
       "3        Cat    Intact Male        3 weeks       Domestic Shorthair Mix   \n",
       "4        Dog  Neutered Male        2 years  Lhasa Apso/Miniature Poodle   \n",
       "\n",
       "         Color  PureBreed  \n",
       "0  Brown/White          0  \n",
       "1  Cream Tabby          0  \n",
       "2   Blue/White          0  \n",
       "3   Blue Cream          0  \n",
       "4          Tan          0  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only the fields we need for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentally reduce problem to a binary lives/dies classification\n",
    "def reduceOutcome(outcome):\n",
    "    return outcome in (\"Adoption\", \"Return_to_owner\", \"Transfer\")\n",
    "\n",
    "# reduce outcome classes to lives/dies\n",
    "def prepareOutcome(df):\n",
    "    df[\"OutcomeTypeReduced\"]=df[\"OutcomeType\"].apply(reduceOutcome)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process our fields to make them suitable for passing to a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate simplified outcomes (lives/dies)\n",
    "def getSimpleOutcome(outcomes):\n",
    "    return [o in (0, 3, 4) for o in outcomes[:,0]]\n",
    "\n",
    "y_train_simple=getSimpleOutcome(y_train)\n",
    "y_test_simple=getSimpleOutcome(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def plotROCCurves(classes, classlabels, y_test_bin, y_test_proba):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(0, len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_test_proba[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    print int(np.ceil(float(len(classes))/2)), 2\n",
    "    f, plts = plt.subplots(int(np.ceil(float(len(classes))/2)), 2, figsize=(10, 10))\n",
    "\n",
    "    plts = plts.ravel()\n",
    "    lw = 2\n",
    "\n",
    "    #classlabels=labelMapper.features[0][1].inverse_transform(classes)\n",
    "\n",
    "    for cls in range(0, len(plts)):#range(0, clf2.n_classes_):\n",
    "        #plt.subplot(3,2,cls+1)\n",
    "        if (cls < len(classes)):\n",
    "            plts[cls].plot(fpr[cls], tpr[cls], color='darkorange',\n",
    "                     lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[cls])\n",
    "            plts[cls].plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "            plts[cls].set_xlim([0.0, 1.0])\n",
    "            plts[cls].set_ylim([0.0, 1.05])\n",
    "            plts[cls].set_xlabel('False Positive Rate')\n",
    "            plts[cls].set_ylabel('True Positive Rate')\n",
    "            plts[cls].set_title('ROC curve - '+classlabels[cls]+\"(AUC = \" + str(round(roc_auc[cls], 2))+ \")\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "        else:\n",
    "            plts[cls].axis(\"off\")\n",
    "\n",
    "    f.subplots_adjust(hspace=0.4)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJkAAAR8CAYAAAA+Q0UaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f840ad550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold= 1e-05 : Re-fitting with  57  features instead of  285\n",
      "f1 score(cv)= [ 0.72491127  0.71857937  0.72820319]\n",
      "log loss(cv)= [-0.61564702 -0.61709199 -0.60193291]\n",
      "f1 score(test)= 0.718632629744\n",
      "log loss(test)= 0.626611151415\n",
      "Threshold= 2.78255940221e-05 : Re-fitting with  57  features instead of  285\n",
      "f1 score(cv)= [ 0.72637994  0.73045713  0.71344935]\n",
      "log loss(cv)= [-0.60983215 -0.60972155 -0.61759419]\n",
      "f1 score(test)= 0.718632629744\n",
      "log loss(test)= 0.626611151415\n",
      "Threshold= 7.74263682681e-05 : Re-fitting with  57  features instead of  285\n",
      "f1 score(cv)= [ 0.72548849  0.71938527  0.72515168]\n",
      "log loss(cv)= [-0.60663903 -0.61870749 -0.60889935]\n",
      "f1 score(test)= 0.718632629744\n",
      "log loss(test)= 0.626611151415\n",
      "Threshold= 0.000215443469003 : Re-fitting with  57  features instead of  285\n",
      "f1 score(cv)= [ 0.72009408  0.72375484  0.72640201]\n",
      "log loss(cv)= [-0.61632962 -0.61045572 -0.60764795]\n",
      "f1 score(test)= 0.718632629744\n",
      "log loss(test)= 0.626611151415\n",
      "Threshold= 0.000599484250319 : Re-fitting with  44  features instead of  285\n",
      "f1 score(cv)= [ 0.72271512  0.72495208  0.71728454]\n",
      "log loss(cv)= [-0.61030109 -0.61138897 -0.61417645]\n",
      "f1 score(test)= 0.717675280589\n",
      "log loss(test)= 0.626170797412\n",
      "Threshold= 0.0016681005372 : Re-fitting with  32  features instead of  285\n",
      "f1 score(cv)= [ 0.72440486  0.72040653  0.72776968]\n",
      "log loss(cv)= [-0.60967003 -0.61588938 -0.60447654]\n",
      "f1 score(test)= 0.718069117789\n",
      "log loss(test)= 0.625440362448\n",
      "Threshold= 0.00464158883361 : Re-fitting with  25  features instead of  285\n",
      "f1 score(cv)= [ 0.72712164  0.71853108  0.72836408]\n",
      "log loss(cv)= [-0.60624074 -0.61926887 -0.60627001]\n",
      "f1 score(test)= 0.719319402181\n",
      "log loss(test)= 0.625405472172\n",
      "Threshold= 0.0129154966501 : Re-fitting with  12  features instead of  285\n",
      "f1 score(cv)= [ 0.72949242  0.72195957  0.72355677]\n",
      "log loss(cv)= [-0.60911819 -0.61385541 -0.60971426]\n",
      "f1 score(test)= 0.71803091611\n",
      "log loss(test)= 0.625390550511\n",
      "Threshold= 0.035938136638 : Re-fitting with  9  features instead of  285\n",
      "f1 score(cv)= [ 0.72337217  0.71968665  0.73166731]\n",
      "log loss(cv)= [-0.62013722 -0.61418958 -0.60259158]\n",
      "f1 score(test)= 0.715964660939\n",
      "log loss(test)= 0.627043825843\n",
      "Threshold= 0.1 : Re-fitting with  3  features instead of  285\n",
      "f1 score(cv)= [ 0.63523916  0.63185949  0.63077777]\n",
      "log loss(cv)= [-0.74352741 -0.75648083 -0.75366299]\n",
      "f1 score(test)= 0.630492993633\n",
      "log loss(test)= 0.758520675031\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define an instance of XGBoost and fit the training set to it\n",
    "fselGB = xgb.XGBClassifier(n_jobs=4)\n",
    "\n",
    "# Fit the classifier to the training set+simple outcomes\n",
    "fselGB.fit(np.hstack((X_train, np.array(y_train_simple)[np.newaxis].T)), y_train[:,0])\n",
    "\n",
    "# Plot feature importances visually\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xgb.plot_importance(fselGB, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# In order to determine which features tp select for our model, we iterate on a threshold value.\n",
    "# Any feature with an importance value smaller than the threshold is removed and the model performance\n",
    "# is determined in terms of f1 score and log loss. \n",
    "# In this way we determine the threshold value at which the performance is maximised and hence which features\n",
    "# to include in our model.\n",
    "thresholds_for_test = np.geomspace(0.00001, 0.1, 10, endpoint=True)\n",
    "f1scorescv=[]\n",
    "loglossescv=[]\n",
    "f1scorestest=[]\n",
    "loglossestest=[]\n",
    "paramsleft=[]\n",
    "for thresh in thresholds_for_test:\n",
    "    support = fselGB.feature_importances_>thresh\n",
    "    print \"Threshold=\", thresh, \": Re-fitting with \", np.sum(support), \" features instead of \", len(support)\n",
    "    \n",
    "    GB2 = xgb.XGBClassifier(n_jobs=4)\n",
    "\n",
    "    \n",
    "    stcv = StratifiedKFold(y_train[:,0],n_folds=3,shuffle=True)\n",
    "    loglosscv = cross_val_score(GB2, np.hstack((X_train, np.array(y_train_simple)[np.newaxis].T))[:, support], y_train[:,0], cv=stcv, scoring=\"neg_log_loss\")\n",
    "    f1cv = cross_val_score(GB2, np.hstack((X_train, np.array(y_train_simple)[np.newaxis].T))[:, support], y_train[:,0], cv=stcv, scoring=\"f1_weighted\")\n",
    "    print \"f1 score(cv)=\", f1cv\n",
    "    print \"log loss(cv)=\", loglosscv\n",
    "    \n",
    "    GB2.fit(np.hstack((X_train, np.array(y_train_simple)[np.newaxis].T))[:, support], y_train[:,0])\n",
    "\n",
    "    preds = GB2.predict(np.hstack((X_test, np.array(y_test_simple)[np.newaxis].T))[:, support])\n",
    "    proba = GB2.predict_proba(np.hstack((X_test, np.array(y_test_simple)[np.newaxis].T))[:, support])\n",
    "\n",
    "    f1score = f1_score(y_test, preds, average=\"weighted\")\n",
    "    logloss = log_loss(y_test, proba, labels=GB2.classes_)\n",
    "    print \"f1 score(test)=\", f1score\n",
    "    print \"log loss(test)=\", logloss\n",
    "\n",
    "    f1scorescv.append(np.mean(f1cv))\n",
    "    loglossescv.append(np.mean(loglosscv))\n",
    "    f1scorestest.append(f1score)\n",
    "    loglossestest.append(logloss)\n",
    "    paramsleft.append(np.sum(support))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  1.00000000e-05,   2.78255940e-05,   7.74263683e-05,\n",
      "         2.15443469e-04,   5.99484250e-04,   1.66810054e-03,\n",
      "         4.64158883e-03,   1.29154967e-02,   3.59381366e-02,\n",
      "         1.00000000e-01]), [57, 57, 57, 57, 44, 32, 25, 12, 9, 3], [0.71863262974430753, 0.71863262974430753, 0.71863262974430753, 0.71863262974430753, 0.71767528058949515, 0.71806911778882199, 0.71931940218122159, 0.71803091610998893, 0.71596466093852451, 0.6304929936333612], [0.62661115141505164, 0.62661115141505164, 0.62661115141505164, 0.62661115141505164, 0.62617079741214365, 0.62544036244839751, 0.6254054721718092, 0.6253905505105436, 0.6270438258428499, 0.7585206750306146]]\n"
     ]
    }
   ],
   "source": [
    "xgbresults = [thresholds_for_test, paramsleft, f1scores, loglosses]\n",
    "print xgbresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-05   2.78255940e-05   7.74263683e-05   2.15443469e-04\n",
      "   5.99484250e-04   1.66810054e-03   4.64158883e-03   1.29154967e-02\n",
      "   3.59381366e-02   1.00000000e-01]\n",
      "[0.71863262974430753, 0.71863262974430753, 0.71863262974430753, 0.71863262974430753, 0.71767528058949515, 0.71806911778882199, 0.71931940218122159, 0.71803091610998893, 0.71596466093852451, 0.6304929936333612]\n",
      "[0.62661115141505164, 0.62661115141505164, 0.62661115141505164, 0.62661115141505164, 0.62617079741214365, 0.62544036244839751, 0.6254054721718092, 0.6253905505105436, 0.6270438258428499, 0.7585206750306146]\n",
      "Will use threshold  0.00877854274188\n",
      "[ True  True False  True  True False False False  True False  True  True\n",
      " False False  True False  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True  True]\n",
      "[[  0.   0.   0. ...,   8.  15.   1.]\n",
      " [  0.   0.   0. ...,   6.  16.   1.]\n",
      " [  0.   0.   0. ...,   4.  14.   0.]\n",
      " ..., \n",
      " [  1.   0.   0. ...,   6.  15.   1.]\n",
      " [  0.   0.   0. ...,   9.   9.   1.]\n",
      " [  1.   1.   0. ...,  10.  15.   1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAJCCAYAAAD6AnJlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f31843ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print thresholds_for_test\n",
    "print f1scores\n",
    "print loglosses\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
    "ax1.plot(thresholds_for_test, f1scorescv, \"bx-\", thresholds_for_test, f1scorestest, \"rx-\")\n",
    "ax2.plot(thresholds_for_test, [abs(loglossescv[i]) for i in range(len(loglossescv))], \"bx-\", thresholds_for_test, loglossestest, \"rx-\")\n",
    "\n",
    "# Select an optimum threshold\n",
    "f1_thresh = np.argsort(f1scorestest)[-1]\n",
    "ll_thresh = np.argsort(loglossestest)[0]\n",
    "\n",
    "# Average the two\n",
    "final_threshold = np.average((thresholds_for_test[f1_thresh], thresholds_for_test[ll_thresh]))\n",
    "\n",
    "# final_support is now a boolean array masking out the most important features.\n",
    "final_support = fselGB.feature_importances_>=final_threshold\n",
    "\n",
    "print \"Will use threshold \", final_threshold\n",
    "print final_support\n",
    "\n",
    "# Save the contents of X_test before feature reduction.\n",
    "#X_test_pre_red = X_test\n",
    "\n",
    "# Reduce the features on the training and test sets\n",
    "X_train = np.hstack((X_train, np.array(y_train_simple)[np.newaxis].T))[:,final_support]\n",
    "X_test = np.hstack((X_test, np.array(y_test_simple)[np.newaxis].T))[:, final_support][:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966018007552\n",
      "0.340696178775\n",
      "(21383, 16)\n",
      "21383\n",
      "[[4]\n",
      " [4]\n",
      " [1]\n",
      " ..., \n",
      " [4]\n",
      " [4]\n",
      " [4]]\n",
      "(5346,)\n",
      "(5346, 2)\n",
      "1 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAJcCAYAAACixjPMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XeclNXd/vHru8vSm4iCNCmiiAXR\nVVABS9SoRGLJYyyxxxYxthgR0F8emoZYUaPRRI0aazR2w2MHUcRFBEFQkOIiSC9LWdjy/f0xg67r\nsszC3nOmfN6v177cmbln5mJxdy/Oue9zzN0FAACA1JITOgAAAAB+ipIGAACQgihpAAAAKYiSBgAA\nkIIoaQAAACmIkgYAAJCCKGlIOWb2gJndFPF77GJmX5pZ/SjfJ9WZ2SQz2yd0DgDAT1HSapGZzTez\njWa2zsy+M7NHzaxxpWMOM7N3zKzIzNaY2Stm1r3SMU3N7C4z+yb+WnPit1sm908UHTM70swWVvWY\nu1/m7sMjjjBI0iPuXlwp16NmVmpmbaq4f0Sl+zqamZtZnQr3nWVmBfG/t8Vm9oaZ9anN4GZ2upl9\naGYbzOy9BI4/y8wWmNl6M3vRzFpUePg2ScNqMx8AoHZQ0mrfSe7eWNIBknpKunHLA2Z2qKT/k/SS\npDaSOkmaKmmCmXWOH1NX0tuS9pF0vKSmkg6TtELSIVGFrlg0Mp2Z1ZN0nqQnKt3fSNJpktZIOns7\nXvdaSXdJGiWplaQOkv4q6Zc7GLmylfH3uTWBTPtI+pukc+KZNsQzbfGypKPMbLdazggA2EGUtIi4\n+3eSxipW1rYYLekxd7/b3YvcfaW7D5U0UdKf4secq9gv91Pc/Qt3L3f3pe4+3N1fr+q9zGwfM3vT\nzFaa2RIzGxy//0ejP5VHr+IjfzeY2TRJ681sqJn9u9Jr321mY+KfNzOzf8RHiL41sxFmlruDX6qq\n/jzf5zazmWb2iwqP1TGz5WZ2YPx27/io0mozm2pmR1Y49nwzmxsftZxnZluKVy9Jq9298kjeaZJW\nKzaydF4NMzeLP+8Kd3/B3de7e4m7v+Lu19fwS1Atd3/L3Z+VtCiBw8+W9Iq7j3P3dZJuknSqmTWJ\nv1axpMmSjqvNjACAHUdJi4iZtZN0gqQ58dsNFRsRe66Kw5+VdGz882Mk/Tf+CzWR92ki6S1J/1Vs\ndG4PxUbiEnWmpP6Smkt6XNKJZtY0/tq5kk6X9GT82H9KKo2/R0/FfrH/tgbvtT2eimfc4ueSlrv7\np2bWVtJrkkZIaiHpD5Kej59v1kjSGEknuHsTxb72n8VfYz9JX1bxXufF3+9pSd22FMEEHSqpvqT/\nJPoEMxsUL5dVftTgvauzj2KjtZIkd/9a0mZJe1Y4ZqakHrX0fgCAWkJJq30vmlmRpEJJSyX9v/j9\nLRT7ei+u4jmLJW0532znrRyzNb+Q9J273+7uxfERuo9r8Pwx7l7o7hvdfYGkTyWdHH/saEkb3H2i\nmbVSrHReHR8lWirpTkln1OC9tseTkgbES64knaUfSuNvJL3u7q/HRxzflFQg6cT44+WS9jWzBu6+\n2N1nxO9vLqmo4puYWQdJR0l60t2XKFZ0azKatrNi5bE00Se4+63u3nxrHzV47+o0Vmz6tqI1kppU\nuF2k2NcEAJBCKGm17+T4yM2Rkrrph/K1SrHSUNW5P7tJWh7/fMVWjtma9pK+3q6kMYWVbj+pH0au\nKhai3SXlSVpcYaTnb5J2repF4yfOb/nosL3h3H2OYiM9J8WL2oBKmf6n0uhTH0m7uft6Sb+WdFk8\n82tm1i3+vFX6cUmRYudszXT3LaNt/5J0lpnlxW+Xxv/8FeUp9ndartjfW8sUPLdvnWLnNVbUVD8u\nqU0Um+YFAKQQSlpE3P19SY8qdvWc4qXhI0n/U8Xhp+uHKcq3JP08Pl2XiEJJXbby2HpJDSvcbl1V\n1Eq3n5N0ZHy69hT9UIgKJW2S1LLCaE9Td69y+QZ3b1zh45sE/yxbs2XK85eSvogXty2ZHq80AtXI\n3W+NZxjr7scqVnpnSXoo/rxp+vF0nxQ7F7Czxa7K/U7SHYoV7BPij38jqWOl53SSVOju5Yr93Rbr\nh1HIbTKzwZXK7I8+En2dbZihClOZ8QtU6kn6qsIxe6vClCgAIDVQ0qJ1l6RjzWzLxQODJJ1nZr83\nsyZmtlP8BPlDJf1v/JjHFSsfz5tZNzPLMbOd47/QT/zpW+hVSa3N7Gozqxd/3V7xxz5T7ByzFmbW\nWtLV2wrs7sskvSfpEUnz3H1m/P7Fil2ZervFlgjJMbMuZnbEdnxdvmdm9St9WBWHPa3Y+W+X64fS\nKMWuzjzJzH5uZrnx5x9pZu3MrJWZDYiX3U2KjSiVxZ83SVLz+DltW6667aLY1bMHxD/2jb/XlinP\n5yX1N7Pj4u/VRtLQeDa5+xpJN0u6z8xONrOGZpZnZieY2eiq/uzuPqpSmf3RRzVfs1yLre9WR1JO\n/M9deZRvi3/Fv0Z941+LYZJecPei+GvVk3SQpDe39n4AgDAoaRGKF57HFLuiTu7+gWInvp+q2Hln\nCxQ7Ab+Pu8+OH7NJsYsHZin2i3OtYqWipaSfnGsW/2V7rKSTJH0nabZi51ZJscI3VdJ8xQrWMwlG\nfzKe4clK958rqa6kLxSbMvy3ajY1W1lbSRsrffxkVDBeED9S7OT/ZyrcX6jY6NpgScsUK7fXK/b/\ndY6k6xS7AnKlpCMk/S7+vM2KjXL+Jv5S50l6yd0/d/fvtnxIulvSL8ysRfx8tjMl3RJ/vY8U+/vY\nUq7l7ndIulax8rYlz0BJL+7A16gq5yj2tbpfUt/451tGCbdMNfeNZ5qh2JTvvxQ7R7LJlq9D3ABJ\n77l7IleKAgCSyNwrz3YBmc/MdpE0XlJPd98YOk8oZvaxpIvcfXroLACAH6OkAQAApCCmOwEAAFIQ\nJQ0AACAFUdIAAABSUKotvLlNLVu29I4dO4aOASCJJk+evNzddwmdAwCSKe1KWseOHVVQUBA6BoAk\nMrMFoTMAQLIx3QkAAJCCKGkAAAApiJIGAACQgihpAAAAKYiSBgAAkIIoaQAAACmIkgYAAJCCKGkA\nAAApiJIGAACQgihpAAAAKYiSBgAAkIIoaQAAACmIkgYAAJCCKGkAAAApiJIGAACQgihpAAAAKYiS\nBgAAkIIoaQAAACmIkgYAAJCCKGkAAAApiJIGAACQgiIraWb2sJktNbPpW3nczGyMmc0xs2lmdmBU\nWQAAANJNlCNpj0o6vprHT5DUNf5xiaT7I8wCAACQVupE9cLuPs7MOlZzyC8lPebuLmmimTU3s93c\nfXG1L7xksnS71V5QAClrSVEj1ckpDx0DAIIIeU5aW0mFFW4vjN/3E2Z2iZkVmFlBUpIBSAlD3viZ\nOo66OnQMAAgispG0BFQ1HOZVHejuD0p6UJLy25vruioPA5BBFixYrX8Oukfl5Xy/A8hOIUfSFkpq\nX+F2O0mLAmUBkGJuvfUDlZaW64wz9g0dBQCCCFnSXpZ0bvwqz96S1mzzfDQAWaNRo7pq0KCOhgzp\nGzoKAARhsfP2I3hhs6ckHSmppaQlkv6fpDxJcvcHzMwk3avYFaAbJF3g7ts85yy/vXlBIdMfQDZY\ns6ZYzZrVl5lNdvf80HkAIJmivLrzzG087pKuiOr9AaS/Zs3qh44AAMGw4wCAlHLXXRP1r39NU2kp\nS28AyG4hr+4EgB9Ztmy9hgx5Rxs2lGiffXbVAQe0Dh0JAIJhJA1Ayrjjjo+0YUOJ+vfvSkEDkPUo\naQBSwooVG3TvvZ9Ikm66qV/gNAAQHiUNQEq4++6PtW7dZh13XBf16tUudBwACI6SBiC41auLNWbM\nx5Kkm29mFA0AJEoagBTw4IOTtWbNJh11VEcdfniH0HEAICVwdSeA4H7/+15q1CiPiwUAoILIdhyI\nCjsOANmHHQcAZCOmOwEEs2FDiVavLg4dAwBSEiUNQDD33/+Jdt/9Lj388JTQUQAg5VDSAASxcWOJ\n/vKXD7V27Sa1atUodBwASDmUNABBPPTQp1qyZL0OPHA3nXhi19BxACDlUNIAJN2mTaUaPXqCpNju\nAmYWOBEApB5KGoCke+SRz/Ttt0Xab79dNWDAXqHjAEBKoqQBSKrNm8t0yy0fSIqNouXkMIoGAFVh\nMVsASbVkyTq1bdtEjRrl6bTTuoeOAwApi5IGIKnat2+mCRMu1PLlGxhFA4BqMN0JIOnMTLvswrIb\nAFAdShqApCgrK9d1143VF18sCx0FANICJQ1AUjz33Be6446JGjDgKZWXs/8uAGwLJQ1A5MrLXSNG\njJMkDRrUh3PRACABlDQAkfvPf2Zqxoxl6tChmc49t0foOACQFihpACLl7ho+PDaKdsMNh6tu3dzA\niQAgPVDSAETqlVe+0tSpS9SmTRNdeGHP0HEAIG1Q0gBEatSo8ZKkP/7xMNWvz9KMAJAoShqASD3+\n+CkaOPBgXXzxQaGjAEBaMff0uhQ+v715QWF6ZQawY8xssrvnh84BAMnESBqASKxcuVHp9o9AAEgl\nlDQAkTjllGd08MEPadas5aGjAEBa4ixeALXu/ffna9y4BWrevL7atGkSOg4ApCVG0gDUui3rol19\ndS81bVovcBoASE+UNAC16sMPC/X22/PUtGk9/f73vULHAYC0RUkDUKu2jKJdeeUh2mmnBoHTAED6\noqQBqDWTJn2r//53jho1ytM11/QOHQcA0hoXDgCoNd98s0YtWjTQb3/bUzvv3DB0HABIayxmC6BW\nFRVtUnm5q1mz+rX2mixmCyAbMZIGoFY1acLVnABQGzgnDcAOmzFjqW6//UOtX785dBQAyBiMpAHY\nYcOHj9Mzz8zQ4sXrdNttx4WOAwAZgZE0ADtk1qzlevbZGcrLy9FVV7EuGgDUFkoagB0ycuR4uUsX\nXHCA2rdvFjoOAGQMShqA7TZnzko9+eTnqlMnRzfe2Dd0HADIKJQ0ANvtllvGq7zcdc45+6tjx+ah\n4wBARqGkAdguCxas1mOPTVNOjmnwYEbRAKC2cXUngO3Svn0zPfXUaZoxY6n22KNF6DgAkHHYcQBA\nymPHAQDZiOlOADVWVLQpdAQAyHiUNAA1snhxkdq2vUOXXvqKyssZ1QaAqFDSANTIX/7yoYqKNmv5\n8o3KybHQcQAgY1HSACRs6dL1euCBAknS0KFc0QkAUaKkAUjYHXd8pI0bS3XSSXuqZ8/dQscBgIxG\nSQOQkBUrNujeeydJkm66qV/gNACQ+ShpABJy110TtX59iY4/fg8dfHDb0HEAIONR0gAkZOHCIkmM\nogFAsrCYLYCEff31SnXpkvzdBVjMFkA2YiQNQMJCFDQAyFaUNADVeuaZ6XrvvflKt1F3AEh3lDQA\nW7Vu3WZdccXrOuqof+rjj78NHQcAsgolDcBWPfBAgVas2KjevdupVy+u6ASAZKKkAajShg0luu22\nDyXFrug0YwsoAEgmShqAKj300GQtWbJeBx20m044YY/QcQAg61DSAPxEcXGpRo9mFA0AQqKkAfiJ\nRx6ZokWLirT//q00YMBeoeMAQFaqEzoAgNTzq191V2HhWvXu3Y5RNAAIhB0HAKQ8dhwAkI2Y7gTw\nvdLScpWUlIWOAQAQJQ1ABU88MU1du96j556bEToKAGQ9ShoASVJZWblGjRqvBQvWaOPG0tBxACDr\nUdIASJKeeWaGZs9eqc6dd9JZZ+0XOg4AZD1KGgCVl7tGjBgnSRo8uI/q1OFHAwCExk9iAHr++S80\nc+ZydejQTOec0yN0HACAKGlA1ouNoo2XJA0adLjq1s0NnAgAIFHSgKz37bdrtW7dZrVp00QXXNAz\ndBwAQBw7DgBZrn37Zvryy4GaM2el6tfnRwIApApG0gCoTp0cdevWMnQMAEAFlDQgS7m77r57opYs\nWRc6CgCgCpQ0IEu9+eZcXX31WB1yyN9VVlYeOg4AoBJKGpCF3F3Dhr0vSbr88nzl5vKjAABSDT+Z\ngSz03nvzNWFCoVq0aKArrjg4dBwAQBUoaUAWGj48trvA1Vf3UpMm9QKnAQBUhZIGZJkPPvhG7747\nX02b1tOVV/YKHQcAsBWUNCDLbBlFu+qqXmrevH7gNACArWHlSiDL3HxzPzVsmKerr+4dOgoAoBrm\n7qEz1Eh+e/OCwvTKDGDHmNlkd88PnQMAkonpTiBLlJSUhY4AAKgBShqQJc4443kNGPCU5s5dFToK\nACABnJMGZIHPP1+iF16Yqfr166hhw7zQcQAACWAkDcgCI0aMlyRdcsmBat26ceA0AIBEUNKADDdz\n5jI999wM1a2bqz/+8fDQcQAACaKkARlu5MjxcpcuvPAAtW3bNHQcAECCKGlABps9e4Weemq66tTJ\n0aBBfULHAQDUABcOABns44+/VZ06OTrnnP21++7NQ8cBANQAJQ3IYL/5zf466qiOMrPQUQAANURJ\nAzIc56EBQHqK9Jw0MzvezL40szlmNqiKxzuY2btmNsXMppnZiVHmAbJFYeEaPf30dJWVlYeOAgDY\nTpGVNDPLlXSfpBMkdZd0ppl1r3TYUEnPuntPSWdI+mtUeYBs8uc/T9CZZz6v669/M3QUAMB2inIk\n7RBJc9x9rrtvlvS0pF9WOsYlbZmLaSZpUYR5gKywaFGR/v73TyVJF13UM3AaAMD2irKktZVUWOH2\nwvh9Ff1J0m/MbKGk1yVdWdULmdklZlZgZgVRBAUyyV/+MkGbNpXptNP21j777Bo6DgBgO0VZ0qq6\nnMwr3T5T0qPu3k7SiZIeN7OfZHL3B909393zI8gJZIwlS9bpgQcmS5KGDu0XOA0AYEdEWdIWSmpf\n4XY7/XQ68yJJz0qSu38kqb6klhFmAjLa7bd/pOLiUg0YsJcOOKB16DgAgB0QZUn7RFJXM+tkZnUV\nuzDg5UrHfCPpZ5JkZnsrVtKWRZgJyFjLl2/QX//6iSTpppsYRQOAdBfZOmnuXmpmAyWNlZQr6WF3\nn2FmwyQVuPvLkq6T9JCZXaPYVOj57l55ShRAAho1ytOoUT/TtGlLlJ/fJnQcAMAOsnTrRPntzQsK\n0yszgB1jZpM5JxVAtmGDdSADsGgtAGQeShqQ5tau3aQ997xXf/rTeyotpawBQKagpAFp7t57J2nu\n3FV67735qlOHb2kAyBT8RAfS2Lp1m3XHHR9J4opOAMg0lDQgjd1//ydasWKjDjusvY4+ulPoOACA\nWkRJA9LUhg0luu22H0bRzKra5AMAkK4oaUCaevDByVq6dL0OPriNfv7zLqHjAABqGSUNSFPvvTdf\nEqNoAJCpIttxAEC0/vOfX2vcuAXq12/30FEAABGgpAFpysx0xBEdQ8cAAESE6U4gzbz77jzNmrU8\ndAwAQMQoaUAaKSkp04UXvqzu3e/ThAnfhI4DAIgQJQ1II088MU3z56/WnnvurN6924WOAwCIECUN\nSBOlpeUaNeoDSdKQIX2Vm8u3LwBkMn7KA2nimWema86clerSZSedeeZ+oeMAACJGSQPSQFlZuUaM\nGC9JGjy4LxupA0AW4Cc9kAaef36mZs1art13b6Zzztk/dBwAQBKwThqQBnr2bK1zz+2hfv06KC8v\nN3QcAEASmLuHzlAj+e3NCwrTKzOAHWNmk909P3QOAEgmpjuBFObuSrd/SAEAagclDUhhr702W716\n/V1vvTU3dBQAQJJR0oAU5e4aNux9ffLJIn3++ZLQcQAASUZJA1LU//3f1/rkk0XaZZeGuvRSTscC\ngGxDSQNSUGwUbZwk6Q9/OEwNG+YFTgQASDZKGpCC3n13vj78sFAtWjTQ5ZczigYA2YiSBqSg4cNj\no2jXXttbTZrUC5wGABACJQ1IMYsWFWnq1O/UvHl9DRx4SOg4AIBA2HEASDFt2jTR/PlXa+rU79Ss\nWf3QcQAAgTCSBqSgpk3rqW/f3UPHAAAEREkDUsgLL8zUhg0loWMAAFIAJQ1IEQUFi3Taac9qv/3u\nV2lpeeg4AIDAKGlAihgxInZF56mndlOdOnxrAkC24zcBkAKmTv1OL730perXr6PrrjssdBwAQAqg\npAEpYMSI8ZKkSy89SK1bNw6cBgCQCihpQGBffLFMzz//herWzdX11zOKBgCIoaQBgY0cOV7u0kUX\n9VTbtk1DxwEApAgWswUCO+WUbpo1a7luuOHw0FEAACnE3D10hhrJb29eUJhemQHsGDOb7O7sNA8g\nqzDdCQSSbv9AAgAkFyUNCOTKK9/QZZe9qkWLikJHAQCkIEoaEMCCBav1t79N1kMPfar16zeHjgMA\nSEGUNCCAP/95gkpLy3XGGfuqa9edQ8cBAKQgShqQZN9+u1b/+McUmUlDhvQNHQcAkKIoaUCSjR49\nQZs3l+lXv+qu7t13CR0HAJCiKGlAEn333To9+OCnkqShQ/sFTgMASGWUNCCJXn99toqLS3Xyyd20\n//6tQscBAKQwdhwAkujCC3vqoIN2U/36fOsBAKrHbwogyXr0aB06AgAgDTDdCSTBypUbNX78gtAx\nAABphJIGJMHdd09Uv36PatCgt0JHAQCkCUoaELE1a4p1990fS5J+8Ys9A6cBAKQLShoQsXvumaQ1\nazbpqKM6qk+fDqHjAADSBCUNiFBR0SbdeedESdJNN7EuGgAgcZQ0IEJ//esnWrlyow4/vL2OPLJj\n6DgAgDRCSQMisn79Zt1++0eSpJtvPkJmFjgRACCdsE4aEJHS0nJdcMEBmjx5sY49tnPoOACANGPu\nHjpDjeS3Ny8oTK/MyG7uzijaDjKzye6eHzoHACQT051AxChoAIDtQUkDatmmTaU64ohH9dBDk1VW\nVh46DgAgTVHSgFr26KOfady4BbrnnkmMogEAthslDahFJSVluuWWDyRJQ4f2U04OJQ0AsH0oaUAt\nevzxaVqwYI323rulTjtt79BxAABpjJIG1JLS0nKNHDlekjRkSF/l5vLtBQDYfvwWAWrJU099rrlz\nV6lr1xb69a/3DR0HAJDmKGlALXniic8lSYMH91WdOnxrAQB2DDsOALXk1VfP1LPPztDpp+8TOgoA\nIANQ0oBakpeXq7PP3j90DABAhmBOBthBn3++RMuWrQ8dAwCQYShpwA5wd5177ovq2PFuTZjwTeg4\nAIAMQkkDdsCrr36lzz77Ts2a1dNBB7UJHQcAkEEoacB2cncNGzZOkvTHPx6u+vU5xRMAUHsoacB2\nGjv2axUULNKuuzbSJZccFDoOACDDUNKA7RAbRXtfkvSHPxyqhg3zAicCAGQaShqwHd55Z54++mih\ndt65gS6//ODQcQAAGYiTaIDt0Lx5ff3sZ5109NGd1Lhx3dBxAAAZyNw9dIYayW9vXlCYXpmRucrL\nXTk5FjpGxjOzye6eHzoHACQT053ADqCgAQCiQkkDauCjjwp18slP69NPF4eOAgDIcJQ0oAaGDx+n\nl176Us8//0XoKACADEdJAxL0ySff6o035qhRozxdc82hoeMAADIcJQ1I0IgR4yVJv/vdwWrZsmHg\nNACATEdJAxLw2Wff6eWXv1SDBnV03XWMogEAokdJAxIwYkRsj85LLz1IrVo1DpwGAJANKGnANixZ\nsk6vvvqV6tXL1fXXHx46DgAgS7DjALANrVo11ldfXamPP16oNm2ahI4DAMgSlDQgAR06NFOHDs1C\nxwAAZBGmO4FqTJr0rcrL2YYMAJB8lDRgK+bMWanDDvuHDjzwbyopKQsdBwCQZShpwFbccst4lZW5\nDjxwN+Xl5YaOAwDIMpQ0oArz56/WY49NU06OafDgvqHjAACyECUNqMKf//yBSkvLddZZ+2mPPVqE\njgMAyEKUNKCShQvX6uGHP5OZNGQIo2gAgDASKmlmVtfM9og6DJAKRo+eoM2by3T66fuoW7eWoeMA\nALLUNkuamfWX9LmkN+O3DzCz/0QdDAilW7eW2m23xoyiAQCCSmQkbZikXpJWS5K7fyYpoVE1Mzve\nzL40szlmNmgrx5xuZl+Y2QwzezLR4EBUfve7g7VgwdXab79WoaMAALJYIjsOlLj7ajOreN82V/c0\ns1xJ90k6VtJCSZ+Y2cvu/kWFY7pKulHS4e6+ysx2rVF6ICIsuQEACC2RkbSZZna6pBwz62Rmd0ma\nmMDzDpE0x93nuvtmSU9L+mWlYy6WdJ+7r5Ikd19ag+xArbrllvEaPvx9rV5dHDoKAAAJlbSBkg6S\nVC7pBUnFkq5K4HltJRVWuL0wfl9Fe0ra08wmmNlEMzu+qhcys0vMrMDMChJ4X6DGVqzYoJEjx+vm\nm9/TV1+tCB0HAICEStrP3f0Gd+8Z/xgk6YQEnmdV3Fd5mrSOpK6SjpR0pqS/m1nznzzJ/UF3z3f3\n/ATeF6ixu+6aqPXrS/Tzn3fRIYdU/rcEAADJl0hJG1rFfUMSeN5CSe0r3G4naVEVx7zk7iXuPk/S\nl4qVNiBpVq8u1pgxkyRJN93UL3AaAABitnrhgJn9XNLxktqa2R0VHmqq2NTntnwiqauZdZL0raQz\nJJ1V6ZgXFRtBe9TMWio2/Tk38fjAjhsz5mOtXbtJRx/dSYcf3iF0HAAAJFV/dedSSdMVOwdtRoX7\niyRVuZxGRe5eamYDJY2VlCvpYXefYWbDJBW4+8vxx44zsy8klUm63t05IQhJs3btJt11V+w6GEbR\nAACpxNyrX03DzOq7e8pc7pbf3rygcJsrgAAJ+fvfP9XFF7+iPn06aNy481VpqRmkCDObzDmpALJN\nIuuktTWzkZK6S6q/5U533zOyVECSXHRRT7Vt20Q77dSAggYASCmJlLRHJY2QdJtiV3VeoMTOSQNS\nnpnphBO4VgUAkHoSubqzobuPlSR3/9rdh0o6KtpYQLQ2bizR7Nmc/ggASF2JlLRNFpsH+trMLjOz\nkySxfRPS2oMPTla3bvdp2LD3Q0cBAKBKiUx3XiOpsaTfSxopqZmkC6MMBUSpuLhUo0d/qPJyV48e\nbKIOAEhN2yxp7v5x/NMiSedIkpm1izIUEKVHHpmiRYuKtP/+rTRgwF6h4wAAUKVqpzvN7GAzOzm+\n0KzMbB8ze0yJbbAOpJzNm8t0yy0fSIqti8YVnQCAVLXVkmZmt0j6l6SzJf3XzIZIelfSVMV2BgDS\nzmOPTVVh4Vp1776LTj1179DtnrihAAAgAElEQVRxAADYquqmO38pqYe7bzSzFortu9nD3b9MTjSg\ndpWUlGnUqPGSpCFD+ionh1E0AEDqqq6kFbv7Rkly95VmNouChnRWVLRZhx/eQfXq1dGvf71P6DgA\nAFRrq9tCmdlqSe9suanY2mhbbsvdT408XRXYFgo7qri4VPXrJ3JhM1IF20IByEbV/aY6rdLte6MM\nAiQLBQ0AkA62+tvK3d9OZhAgKuXlrvPOe1FnnrmvTjhhD67oBACkhUR2HADS2gsvzNQTT0zT5Ze/\nppIStp0FAKQHShoyWnm5a/jwcZKkQYMOV926uYETAQCQmIRLmpnVizIIEIVXXvlS06YtUdu2TXTh\nhT1DxwEAIGHbLGlmdoiZfS5pdvx2DzO7J/JkwA5y/2EU7Y9/PFz16nHBAAAgfSQykjZG0i8krZAk\nd5+q2HIcQEp74405mjx5sVq1aqSLLz4wdBwAAGokkZKW4+4LKt1XFkUYoDbdfffHkqTrrz9MDRrk\nBU4DAEDNJDL/U2hmh0hyM8uVdKWkr6KNBey4Z5/9lR54oECXXcYaqACA9LPVHQe+P8BsV8WmPI+J\n3/WWpIHuvjzibFVixwEg+7DjAIBslMhIWqm7nxF5EqCWFBauUcuWDZniBACktUTOSfvEzF43s/PM\nrEnkiYAddP75L6lz5zGaOHFh6CgAAGy3bZY0d+8iaYSkgyR9bmYvmhkja0hJEyZ8o3femacNG0rU\nrVvL0HEAANhuCS1m6+4fuvvvJR0oaa2kf0WaCthOW9ZFu+qqXmrevH7gNAAAbL9EFrNtbGZnm9kr\nkiZJWibpsMiTATU0adK3Gjv2azVuXFdXX907dBwAAHZIIhcOTJf0iqTR7j4+4jzAdtsyinbFFQer\nRYsGgdMAALBjEilpnd29PPIkwA6YMmWxXn31KzVsmKdrrz00dBwAAHbYVkuamd3u7tdJet7MfrIw\nmbufGmkyoAaKijare/dddPzxXbTrro1CxwEAYIdVN5L2TPy/9yYjCLAj+vXbXZ9/frmKi0tDRwEA\noFZstaS5+6T4p3u7+4+KmpkNlPR2lMGAmsrJMTVsyAK2AIDMkMgSHBdWcd9FtR0E2B6zZi3XFVe8\npm++WRM6CgAAtaq6c9J+LekMSZ3M7IUKDzWRtDrqYEAiRo4cryeemKbyctf99/8idBwAAGpNdeek\nTZK0QlI7SfdVuL9I0pQoQwGJmDNnpZ588nPVqZOjG27oEzoOAAC1qrpz0uZJmifpreTFARI3atR4\nlZe7zj+/hzp2bB46DgAAtaq66c733f0IM1slqeISHCbJ3b1F5OmArZg3b5Uee2yqcnNNgwf3DR0H\nAIBaV91051Hx/7JLNVLOrbd+oLIy1znn7K8uXfj3AgAg82z16s4Kuwy0l5Tr7mWSDpV0qSRWC0Uw\ny5dv0KOPTpWZNGQIo2gAgMyUyBIcL0pyM+si6TFJe0t6MtJUQDVatmyoDz+8UHfc8XPttRcDvQCA\nzJTI3p3l7l5iZqdKusvdx5gZV3ciqIMOaqODDmoTOgYAAJFJZCSt1Mz+R9I5kl6N38ey7giisJBF\nawEA2SHRHQeOkjTa3eeaWSdJT0UbC/ippUvXa6+97tUxxzymTZvYoxMAkNm2Od3p7tPN7PeS9jCz\nbpLmuPvI6KMBP3b77R9q48ZSNWyYp3r1EpmpBwAgfW3zN52Z9ZX0uKRvFVsjrbWZnePuE6IOB2yx\nfPkG3XffJ5Kkm27qFzgNAADRS2Q44k5JJ7r7F5JkZnsrVtryowwGVHTXXRO1fn2JTjhhDx18cNvQ\ncQAAiFwi56TV3VLQJMndZ0qqG10k4MdWrdqoe+6ZJIlRNABA9khkJO1TM/ubYqNnknS22GAdSTRm\nzMdau3aTjjmmsw49tH3oOAAAJEUiJe0ySb+X9EfFzkkbJ+meKEMBFeXkmBo2zGMUDQCQVczdt/6g\n2X6Sukia4e6zk5aqGvntzQsKt54ZmWnVqo3aaacGoWMgEDOb7O6cBwsgq2z1nDQzG6zYllBnS3rT\nzC5MWiqgEgoaACDbVDfdebak/d19vZntIul1SQ8nJxYgPfroZyovd51zzv7Ky8sNHQcAgKSqrqRt\ncvf1kuTuy8wskStBgVqxYUOJbrjhLS1dul7t2jXVccd1CR0JAICkqq6kdTazF+Kfm6QuFW7L3U+N\nNBmy2oMPTtbSpeuVn99Gxx7bOXQcAACSrrqSdlql2/dGGQTYori4VKNHxza0uOmmfjKzwIkAAEi+\nrZY0d387mUGALR5+eIoWL16nHj1a6aST9gwdBwCAIDjPDCll8+Yy3XrrB5IYRQMAZDdKGlLKU099\nrsLCtdpnn110yil7h44DAEAwiew4IEkys3ruvinKMMCZZ+6nkpJy7bZbY+XkMIoGAMhe2yxpZnaI\npH9Iaiapg5n1kPRbd78y6nDIPnXr5uq3vz0wdAwAAIJLZLpzjKRfSFohSe4+VdJRUYZC9iktLdfy\n5RtCxwAAIGUkUtJy3H1BpfvKogiD7PXMM9PVseNduvPOj0JHAQAgJSRyTlphfMrTzSxX0pWSvoo2\nFrJJWVm5RowYr/XrS9S0ab3QcQAASAmJjKRdLulaSR0kLZHUO34fUCuef36mZs1art13b6ZzzukR\nOg4AAClhmyNp7r5U0hlJyIIsVF7uGjFinCRp0KA+qluXjdQBAJASu7rzIUle+X53vySSRMgqL700\nS59/vlRt2zbRBRccEDoOAAApI5Fz0t6q8Hl9SadIKowmDrKJu2v48Ngo2g03HK569RJetg8AgIyX\nyHTnMxVvm9njkt6MLBGyxqpVxWrevL5at27M2mgAAFSyPUMXnSTtXttBkH1atGigd945T0uWrFOD\nBnmh4wAAkFISOSdtlX44Jy1H0kpJg6IMhezSqlXj0BEAAEg51S7BYWYmqYekXeIfO7l7Z3d/Nhnh\nkJncXUOHvqPPPvsudBQAAFJWtSXN3V3Sf9y9LP7xk6s8gZp69935GjlyvI455jEVF5eGjgMAQEpK\nZDHbSWbGWd2oNVuu6Lz66t6qX58rOgEAqMpWf0OaWR13L5XUR9LFZva1pPWSTLFBNoobamz8+AV6\n7735atasnq688pDQcQAASFnVDWNMknSgpJOTlAVZYMso2lVX9VKzZvUDpwEAIHVVV9JMktz96yRl\nQYb7+OOFevPNuWrcuK6uuqp36DgAAKS06kraLmZ27dYedPc7IsiDDDZq1AeSpIEDD1aLFg0CpwEA\nILVVV9JyJTVWfEQN2FFjxhyv9u2b6tprDw0dBQCAlGdbW1XDzD5NxYsD8tubFxSyEgiQTcxssrvn\nh84BAMlU3RIcjKChVqxZU6zycoo1AAA1UV1J+1nSUiCjXXLJq+rR4wFNnrwodBQAANLGVs9Jc/eV\nyQyCzDRz5jI999wM5eXlqnVr9ugEACBRiew4AGy3kSPHy1266KKeatu2aeg4AACkDUoaIvPVVyv0\n1FPTlZeXo0GD+oSOAwBAWqGkITKjRo1XebnrvPN6qEOHZqHjAACQVihpiMTcuav0xBPTlJtruvHG\nvqHjAACQdqpbzBbYbnPmrFTLlg11/PF7qHPnnULHAQAg7VDSEInjjuuiefOu0rp1m0NHAQAgLVHS\nEJkGDfLUoEFe6BgAAKQlzklDrVq0qEijRo3X2rWbQkcBACCtUdJQq0aPnqAhQ97RlVe+EToKAABp\njZKGWvPdd+v0t79NliRdd92hgdMAAJDeKGmoNbff/qGKi0t18sndtP/+rULHAQAgrVHSUCuWLVuv\nv/61QJI0dCjrogEAsKMoaagVd945URs2lOjEE7vqoIPahI4DAEDao6Rhh61eXax7750kSbrppn6B\n0wAAkBkiLWlmdryZfWlmc8xsUDXH/crM3Mzyo8yDaDRrVk9PPnmarrmmt3r3bhc6DgAAGcHcPZoX\nNsuV9JWkYyUtlPSJpDPd/YtKxzWR9JqkupIGuntBda+b3968oDCazABSk5lNdnf+EQcgq0Q5knaI\npDnuPtfdN0t6WtIvqzhuuKTRkoojzIKIsO0TAADRiLKktZVUWOH2wvh93zOznpLau/ur1b2QmV1i\nZgVmVu0oG5KrqGiTunQZo3PP/Y82biwJHQcAgIwSZUmzKu77fp7SzHIk3Snpum29kLs/6O75THek\nlvvvL9DSpev19derVL8+28ACAFCboixpCyW1r3C7naRFFW43kbSvpPfMbL6k3pJe5uKB9LB+/Wbd\ndtuHkqSbb+4ns6o6OQAA2F5RlrRPJHU1s05mVlfSGZJe3vKgu69x95bu3tHdO0qaKGnAti4cQGp4\n8MHJWrZsgw4+uI2OO65L6DgAAGScyEqau5dKGihprKSZkp519xlmNszMBkT1vojexo0lGj16yyja\nEYyiAQAQgUhPJHL31yW9Xum+m7dy7JFRZkHt+cc/pui779apZ8/W6t+/a+g4AABkJHYcQI3NnbtK\nZrHdBRhFAwAgGpEtZhsVFrNNDbNnr1CXLi2Uk0NJQ/RYzBZANmLdBGyXrl13Dh0BAICMxnQnEvbG\nG7M1duwcpdvoKwAA6YiShoSUlpbryivf0PHH/0uvvvpV6DgAAGQ8ShoS8vTT0/X116u0xx4tdMIJ\nXNEJAEDUKGnYprKyco0cOV6SNHhwH9Wpw/82AABEjd+22KZ///sLzZq1XB07NtdvfrN/6DgAAGQF\nShqqVV7uGjEiNop24419lJeXGzgRAADZgZKGar344ixNn75U7ds31Xnn9QgdBwCArME6aajWUUd1\n1J/+dIR237256tXjfxcAAJKFHQcApDx2HACQjZjuRJXcXZs2lYaOAQBA1qKkoUpjx36tzp3H6JFH\npoSOAgBAVqKk4SfcXcOGva9Fi4q0bNmG0HEAAMhKlDT8xDvvzNNHHy3Uzjs30O9+d3DoOAAAZCVK\nGn5i+PBxkqRrrumtxo3rBk4DAEB2oqThR8aNW6D331+g5s3ra+DAQ0LHAQAga1HS8CNbRtGuuqqX\nmjWrHzgNAADZi5KG761eXayFC9eqSZO6uuqqXqHjAACQ1VhCHt9r3ry+pk+/XDNnLtdOOzUIHQcA\ngKzGSBp+JDc3R/vuu2voGAAAZD1KGiRJDz44WQsXrg0dAwAAxFHSoM8++06XXvqq9tvvfm3YUBI6\nDgAAECUNkkaMiF3Red55PdSwYV7gNAAAQKKkZb0ZM5bq+ednql69XP3xj4eHjgMAAOIoaVlu5Mjx\nkqSLLuqpNm2aBE4DAAC2oKRlsS+/XK5nnpmhvLwc3XBDn9BxAABABZS0LDZq1AcqL3edf/4B6tCh\nWeg4AACgAhazzWIDBx6sNWuKNWgQo2gAAKQac/fQGWokv715QWF6ZQawY8xssrvnh84BAMnEdGcW\nKi0tDx0BAABsAyUtC1155es67rjHNWPG0tBRAADAVnBOWpZZuHCtHn74M5WUlCknx0LHAQAAW8FI\nWpYZPXqCNm8u0//8zz7ae+9dQscBAABbQUnLIosXF+mhhz6VJA0d2jdwGgAAUB1KWha57bYPVVxc\nqlNO6ab99msVOg4AAKgGJS1LLFu2Xg88MFmSNHRov8BpAADAtlDSssSkSd/K3dW/f1cdeOBuoeMA\nAIBt4OrOLNG//56aN+8qrV9fEjoKAABIACUti7Rq1Th0BAAAkCCmOzPc6tXFeuyxqSopKQsdBQAA\n1AAlLcPdc8/HOu+8F3XhhS+HjgIAAGqAkpbBioo26c47J0qSLrqoZ+A0AACgJihpGey++z7RqlXF\n6tOng444YvfQcQAAQA1Q0jLU+vWbdfvtH0mSbrqpn8zYpxMAgHRCSctQDzxQoOXLN6hXr7Y69tjO\noeMAAIAaoqRloI0bS/SXv3woiVE0AADSFeukZaDc3Bz97/8eqbFjv9aJJ3YNHQcAAGwHc/fQGWok\nv715QWF6ZQawY8xssrvnh84BAMnEdGeGKS+nwAIAkAkoaRlk8+Yy9ejxgG688S1t3MgenQAApDNK\nWgZ5/PGpmj59qV5++SvVq8fphgAApDNKWoYoLS3XqFEfSJKGDOmrnByu6AQAIJ1R0jLEk09+rrlz\nV2nPPXfWr3+9T+g4AABgB1HSMkBZWblGjhwvSRo8uI9yc/lrBQAg3fHbPAM8++wMffXVCnXq1Fxn\nnbVf6DgAAKAWUNIywNtvz5MkDR7cV3l5uYHTAACA2sBithli/PgF6tWrnerWpaQh87CYLYBsxDoN\nGaJv391DRwAAALWI6c40NmnSt5o2bUnoGAAAIAKUtDTl7vrd715Tjx4P6OWXvwwdBwAA1DJKWpr6\n73/naPLkxdp110Y65pjOoeMAAIBaRklLQ+6uYcPGSZKuv/4wNWyYFzgRAACobZS0NPT22/M0ceJC\n7bxzA112GRe8AQCQiShpaWjYsPclSdddd6gaN64bOA0AAIgCJS3NvP/+fI0f/4122qm+rrjikNBx\nAABARFgnLc107NhcF198oDp1aq6mTeuFjgMAACLCjgMAUh47DgDIRkx3ppF0K9QAAGD7UdLSxCef\nfKuePf+ml16aFToKAABIAkpamhg+fJymTl2iDz8sDB0FAAAkASUtDUyZslivvPKVGjSoo+uuOyx0\nHAAAkASUtDQwYsR4SdJll+Vr110bBU4DAACSgZKW4qZPX6oXXpipevVydf31jKIBAJAtKGkpbsSI\n2B6dF198oHbbrUngNAAAIFkoaSmsqGiT3ntvvurWzdUNN/QJHQcAACQROw6ksCZN6unrr3+vjz5a\nqHbtmoaOAwAAkoiRtBTXqFFdHXNM59AxAABAklHSUtQbb8xWUdGm0DEAAEAglLQUNH/+ag0Y8LT2\n2OMerVu3OXQcAAAQACUtBd166wcqLS3Xccd1UePGdUPHAQAAAVDSUkxh4Ro9/PAUmUlDhvQNHQcA\nAARCSUsxo0dPUElJuU4/fR9169YydBwAABAIJS2FLF5cpIce+lSSNHRov8BpAABASOlX0lodFDpB\nZG677UNt2lSm007bW/vuu2voOAAAIKD0K2kZ7OijO+mgg3ZjFA0AALDjQCrp339PnXhiV5lZ6CgA\nACAwRtJSDAUNAABIlLSU8L//+54uuOAlzZu3KnQUAACQIihpga1atVF33DFRjz76mRYvXhc6DgAA\nSBGUtMDGjPlYa9du0tFHd9Jhh7UPHQcAAKQISlpAa9du0l13fSxJuvlmrugEAAA/oKQFdN99k7R6\ndbH69u2gI47oGDoOAABIIZGWNDM73sy+NLM5ZjaoisevNbMvzGyamb1tZrtHmSeVrFu3WXfcMVGS\ndPPNRwROAwAAUk1kJc3MciXdJ+kESd0lnWlm3SsdNkVSvrvvL+nfkkZHlSfVvP32XK1YsUG9e7fT\nz37WKXQcAACQYqJczPYQSXPcfa4kmdnTkn4p6YstB7j7uxWOnyjpNxHmSSm//GU3TZ/+OxUXl7I2\nGgAA+IkoS1pbSYUVbi+U1Kua4y+S9EZVD5jZJZIukaQOHTrUVr7gunffJXQEAACQoqI8J62q4SGv\n8kCz30jKl/SXqh539wfdPd/d83fZJb2LTXFxqd5+e67cq/xSAAAASIq2pC2UVHHhr3aSFlU+yMyO\nkTRE0gB33xRhnpTw8MNTdMwxj+vii18JHQUAAKSwKEvaJ5K6mlknM6sr6QxJL1c8wMx6SvqbYgVt\naYRZUsLmzWW69dYPJEnHH79H4DQAACCVRVbS3L1U0kBJYyXNlPSsu88ws2FmNiB+2F8kNZb0nJl9\nZmYvb+XlMsI///mZCgvXqnv3XXTqqXuHjgMAAFJYlBcOyN1fl/R6pfturvD5MVG+fyopKSnTLbfE\nRtGGDu2rnByu6AQAAFvHjgNJ8q9/fa5581Zrzz131umn7xM6DgAASHGUtCQoKyvXqFHjJUlDhvRV\nbi5fdgAAUD3aQhJs3lymM8/cVwceuJvOOmu/0HEAAEAasHRbrys/P98LCgpCx9gu7s7uAsB2MLPJ\n7p4fOgcAJBMjaUlEQQMAAImipEWovNzVv/+TuvfeSdq0qTR0HAAAkEYoaRF6+eUv9frrs79fwBYA\nACBRlLSIuLuGDXtfknTDDYerXr1Il6QDAAAZhpIWkddfn60pU75Tq1aN9NvfHhg6DgAASDOUtAjE\nRtHGSZKuv/4wNWiQFzgRAABIN5S0CLz55lxNmvStWrZsqMsuY9UAAABQc5S0CDz22FRJ0nXXHapG\njeoGTgMAANIRZ7NH4J//PFn9+3dV//57ho4CAADSFCUtArm5OTrzTLZ/AgAA24/pzlo0e/YKLVpU\nFDoGAADIAJS0WnTllW+oc+e79dprX4WOAgAA0hwlrZZMmvStxo79Wnl5uTr00Pah4wAAgDRHSasl\nw4fH1kUbOPBgtWjRIHAaAACQ7ihpteDTTxfr1Ve/UsOGebr22kNDxwEAABmAklYLRoyIjaJdfnm+\ndtmlUeA0AAAgE1DSdtC0aUv0n//MUv36dfSHPxwWOg4AAMgQrJO2g+rUyVH//l3VpctOat26ceg4\nAAAgQ1DSdlD37rvo1VfPUllZeegoAAAggzDdWUtyc/lSAgCA2kOz2E6zZ69Q//5P6qOPCkNHAQAA\nGYjpzu00atQHev312dptt8YsXgsAAGodI2nbYd68VXr88anKzTXdeGOf0HEAAEAGoqRth1tu+UBl\nZa6zz95fXbq0CB0HAABkIEpaDX3zzRo9+uhnMpMGD2YUDQAARIOSVkN//vMHKikp1xln7Ku99moZ\nOg4AAMhQlLQaWL9+s558crrMpCFD+oaOAwAAMhhXd9ZAo0Z1NXPmFRo7do722WfX0HEAAEAGYySt\nhlq3bqzzzjsgdAwAAJDhKGkJmjJlsUpL2foJAAAkByUtAcuXb1Dfvo9o773v05o1xaHjAACALEBJ\nS8Cdd36k9etL1LVrCzVrVj90HAAAkAUoaduwcuVG3XPPJEnSTTf1C5wGAABkC0raNowZ87GKijbr\nmGM6s0cnAABIGkpaNdasKdZdd02UJN18M6NoAAAgeShp1bj33klas2aTjjhid/Xtu3voOAAAIItQ\n0qrRvn0ztW/fVDfffEToKAAAIMuYu4fOUCP5+fleUFCQtPfbvLlMeXk5MrOkvSeAHzOzye6eHzoH\nACQT20JtQ926uaEjAACALMR0ZxUefHCyhg59RytWbAgdBQAAZClG0iopLi7Vn/70nhYvXqdevdrq\npJP2Ch0JAABkIUbSKvnHPz7V4sXrdMABrfWLX+wZOg4AAMhSlLQKNm0q1a23TpAU212AiwUAAEAo\nlLQK/vnPqVq4cK323XdXnXxyt9BxAABAFqOkxZWUlOmWWz6QJA0d2lc5OYyiAQCAcChpca+/Plvz\n569Wt24t9atfdQ8dBwAAZDmu7owbMGAvvf32uSorK1duLt0VAACERUmLMzMdfXSn0DEAAAAkMd2p\nsrJyzZy5LHQMAACAH8n6kvbvf3+h7t3/qmuu+W/oKAAAAN/L6pJWXu4aMWK8JKlbt5aB0wAAAPwg\nq0vaiy/O0vTpS9WuXVOdf/4BoeMAAAB8L2tLmrtrxIhxkqQbbjhc9epxDQUAAEgdWVvSXntttqZM\n+U6tWzfWRRf1DB0HAADgR7KypLm7hv//9u4+yKq6juP4+7OICkmYCqWZookmrghESqmVWY7GJNU4\nro5oMBpWWj6kjQVNj9OTVmQIQmpgY2laFJkNPWH4wKqoiYiSSFpUJAiZwKorfPvjnK3bssueu+y9\n59x7P6+Zndl77rn3fL57d2e++/udc35fSkbRPvWptzFgQP+cE5mZmZn9v4Zs0traXqG5eQj77TeI\n888fm3ccMzMzs+005IlYAwf25/rrJ9DW1u5RNDMzMyukhhxJ6+AGzczMzIqq4Zq0Cy74JfPnP862\nbZF3FDMzM7NuNVSTtnjxM8ycuZTJk3/OCy+8lHccMzMzs241VJPWcUXnRRcdw+DBu+ecxszMzKx7\nDdOktbau4be/Xc2gQbty0UXj8o5jZmZmtkMN06R1jKJdeOHR7LXXgJzTmJmZme1YQzRpDz74d+64\n40kGDuzPJZd4FM3MzMyKryGatOnT7wPgYx8by5Ahr8o5jZmZmVnPGuJmtrNmjWfkyKGcffZReUcx\nMzMzy6QhmrQ99tiVyy8/Nu8YZmZmZpnV9XTn2rWb2LTp5bxjmJmZmZWtrpu0Sy9dyLBh01m4cFXe\nUczMzMzKUrfTnStXrufmm5ezyy5NHH74kLzjmJmZmZWlbkfSvvKVu4mASZNGccABg/OOY2ZmZlaW\numzSnnpqAzfdtIx+/cQVVxyXdxwzMzOzstVlk/bVr97N1q3BxIkjOfjg1+Qdx8zMzKxsddekPfPM\nv5g37xGamsRnPnN83nHMzMzMeqXuLhx47rk2mpuHMmLEEA49dO+845iZmZn1St01aWPG7MtDD03x\n/dHMzMysptXddCeAJAYN2i3vGGZmZma9VjdN2tq1mzj//F/w1FMb8o5iZmZmttPqZrrzqqvuZc6c\nh1i/vo2f/OT0vOOYmZmZ7ZS6GElbt24zs2YtBWDqVF/RaWZmZrWvLpq0b31rCVu2tDN+/HDGjNk3\n7zhmZmZmO63mm7QNG9qYMeMBAD772bfnnMbMzMysb9R8kzZ9eiubNr3MSSe9kWOO2T/vOGZmZmZ9\noqabtLa2dmbMuB/wKJqZmZnVl5q+unPAgP4sXjyZ+fMf57jjDsg7jpmZmVmfqekmDaC5eSjNzUPz\njmFmZmbWp2p2uvNvf/s3EZF3DDMzM7OKqMkmbfPmlxk9ejbHH/99Nm5syzuOmZmZWZ+rySZt9uwH\nWbduC+3t29hzz93zjmNmZmbW52quSdu2LbjyynuB5IpOSTknMjMzM+t7NdekrV+/hbVrNzF69OsY\nP3543nHMzMzMKqKiTZqkkyWtlLRK0hVdPL+bpFvS5++TNKyn91y7dhPgUTQzMzOrbxVr0iT1A64B\nTgFGAGdKGtFpt3OBjVfhIzEAAAgISURBVBFxCPBt4Os9vW97+1aOPHIoEya8qa8jm5mZmRVGJUfS\njgZWRcTqiHgZuBmY0GmfCcC89PvbgBPVw/BYU1MT06a9naYmj6KZmZlZ/arkzWxfD/y15PEa4Jju\n9omIVyQ9D+wNrC/dSdIUYEr68KWWlublLS0VyVxt+9Cp1hpWL7XUSx1QX7UclncAM7Nqq2ST1tVQ\nV+e7z2bZh4iYA8wBkLQ0IsbufLz8uZbiqZc6oP5qyTuDmVm1VXK6cw3whpLH+wN/724fSbsAg4EN\nFcxkZmZmVhMq2aQ9AAyXdJCkXYEzgAWd9lkAfCj9/jTg9+G1nszMzMwqN92ZnmN2IbAQ6AfcEBGP\nSfoisDQiFgDXAz+QtIpkBO2MDG89p1KZc+Baiqde6gDXYmZW0+SBKzMzM7PiqbkVB8zMzMwagZs0\nMzMzswIqbJNWiSWl8pChjkslrZC0TNLvJB2YR84seqqlZL/TJIWkwt7+IUstkk5PP5vHJP2w2hmz\nyvA7doCkRZIeTn/P3ptHzp5IukHSs5KWd/O8JF2d1rlM0phqZzQzq6ZCNmmVWlKq2jLW8TAwNiJG\nkqy68I3qpswmYy1IGgR8Arivugmzy1KLpOHAp4FjI+II4OKqB80g4+cyDfhxRIwmuThnZnVTZjYX\nOHkHz58CDE+/pgCzqpDJzCw3hWzSqNCSUjnosY6IWBQRW9KHrST3kyuiLJ8JwJdIGs0XqxmuTFlq\n+TBwTURsBIiIZ6ucMasstQTw6vT7wWx/v8JCiIjF7Pg+iROAGyPRCuwpad/qpDMzq76iNmldLSn1\n+u72iYhXgI4lpYokSx2lzgV+VdFEvddjLZJGA2+IiNurGawXsnwuhwKHSrpHUqukHY3w5ClLLZ8H\nJkpaA9wBfLw60fpcuX9PZmY1rZLLQu2MPltSKmeZM0qaCIwF3lHRRL23w1okNZFMO0+qVqCdkOVz\n2YVkWu2dJKObd0lqjoh/VThbubLUciYwNyK+KemtJPcmbI6IbZWP16dq4W/ezKzPFHUkrV6WlMpS\nB5LeDUwFTo2Il6qUrVw91TIIaAbulPQ0MA5YUNCLB7L+fv08Itoj4s/ASpKmrWiy1HIu8GOAiFgC\n7E6y+HqtyfT3ZGZWL4rapNXLklI91pFOEc4madCKet4T9FBLRDwfEftExLCIGEZyft2pEVHEhbGz\n/H79DDgBQNI+JNOfq6uaMpsstfwFOBFA0uEkTdq6qqbsGwuAc9KrPMcBz0fEP/IOZWZWKYWc7qzg\nklJVlbGOK4E9gFvT6x7+EhGn5ha6GxlrqQkZa1kInCRpBbAVuDwinssvddcy1vJJ4HuSLiGZHpxU\nwH9okPQjkunlfdLz5z4H9AeIiGtJzqd7L7AK2AJMziepmVl1eFkoMzMzswIq6nSnmZmZWUNzk2Zm\nZmZWQG7SzMzMzArITZqZmZlZAblJMzMzMysgN2kNSNJWSX8s+Rq2g32HSVreB8e8U9JKSY+kSy0d\n1ov3+Iikc9LvJ0nar+S567pa8H0ncz4gaVSG11wsaeDOHtvMzKyUm7TG1BYRo0q+nq7Scc+KiKOA\neST3hytLRFwbETemDycB+5U8d15ErOiTlP/LOZNsOS8G3KSZmVmfcpNmwH9HzO6S9FD69bYu9jlC\n0v3p6NsyScPT7RNLts+W1K+Hwy0GDklfe6KkhyU9KukGSbul278maUV6nKvSbZ+XdJmk00jWOb0p\nPeaAdARsrKSPSvpGSeZJkr7by5xLKFnAW9IsSUslPSbpC+m2T5A0i4skLUq3nSRpSfpzvFXSHj0c\nx8zMbDtu0hrTgJKpzvnptmeB90TEGKAFuLqL130E+E5EjCJpktakywy1AMem27cCZ/Vw/PcBj0ra\nHZgLtETEkSQrYHxU0l7AB4AjImIk8OXSF0fEbcBSkhGvURHRVvL0bcAHSx63ALf0MufJJMtDdZga\nEWOBkcA7JI2MiKtJ1o88ISJOSJeQmga8O/1ZLgUu7eE4ZmZm2ynkslBWcW1po1KqPzAjPQdrK8la\nlZ0tAaZK2h/4aUQ8KelE4M3AA+myVgNIGr6u3CSpDXga+DhwGPDniPhT+vw84AJgBvAicJ2kXwK3\nZy0sItZJWp2u7fhkeox70vctJ+erSJZZGlOy/XRJU0j+bvYFRgDLOr12XLr9nvQ4u5L83MzMzMri\nJs06XAL8EziKZIT1xc47RMQPJd0HjAcWSjoPEDAvIj6d4RhnlS64LmnvrnZK16M8mmRR8DOAC4F3\nlVHLLcDpwBPA/IgIJR1T5pzAI8DXgGuAD0o6CLgMeEtEbJQ0l2Sh8s4E/CYiziwjr5mZ2XY83Wkd\nBgP/iIhtwNkko0j/R9LBwOp0im8BybTf74DTJA1N99lL0oEZj/kEMEzSIenjs4E/pOdwDY6IO0hO\nyu/qCssXgEHdvO9PgfcDZ5I0bJSbMyLaSaYtx6VTpa8GNgPPS3otcEo3WVqBYztqkjRQUlejkmZm\nZjvkJs06zAQ+JKmVZKpzcxf7tADLJf0ReBNwY3pF5TTg15KWAb8hmQrsUUS8CEwGbpX0KLANuJak\n4bk9fb8/kIzydTYXuLbjwoFO77sRWAEcGBH3p9vKzpme6/ZN4LKIeAR4GHgMuIFkCrXDHOBXkhZF\nxDqSK09/lB6nleRnZWZmVhZFRN4ZzMzMzKwTj6SZmZmZFZCbNDMzM7MCcpNmZmZmVkBu0szMzMwK\nyE2amZmZWQG5STMzMzMrIDdpZmZmZgX0H4JsglvRngIJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f5c761f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#preclf = MultinomialNB()\n",
    "preclf = KNeighborsClassifier(weights=\"distance\", n_neighbors=100, n_jobs=-1)\n",
    "preclf.fit(X_train[:,:-1], y_train_simple) # slice out the simpleoutcome field\n",
    "\n",
    "prepreds = preclf.predict(X_test)\n",
    "preproba = preclf.predict_proba(X_test)\n",
    "\n",
    "print f1_score(y_test_simple, prepreds)\n",
    "print log_loss(y_test_simple, preproba)\n",
    "\n",
    "print X_train.shape\n",
    "print len(y_train_simple)\n",
    "print y_train\n",
    "\n",
    "print prepreds.shape\n",
    "print preproba.shape\n",
    "\n",
    "plotROCCurves([1], [\"Lives\"], np.transpose(prepreds[np.newaxis]), np.transpose(preproba[:,1][np.newaxis]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#print y_test_simple[np.newaxis]\n",
    "\n",
    "X_test = np.hstack((X_test, np.array(y_test_simple)[np.newaxis].T))[:,final_support]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgeDays' 'SimpleOutcome' 'OutcomeHour' 'HasName' 'Neutered' 'AnimalType'\n",
      " 'OutcomeDay' 'IsWeekend' 'OutcomeMonth' 'DaySegment_HR_3'\n",
      " 'DaySegment_HR_2' 'Sex_female' 'DaySegment_HR_6' u'Breed_poodle'\n",
      " 'DaySegment_HR_0' 'PureBreed']\n"
     ]
    }
   ],
   "source": [
    "sortedIndexes = np.argsort(fselGB.feature_importances_)[::-1]\n",
    "colnames= X_test_df.columns.values\n",
    "colnames = np.append(colnames, \"SimpleOutcome\")\n",
    "\n",
    "print colnames[sortedIndexes][final_support[sortedIndexes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 2, 2, 1, 2, 2, 1, 2, 2, 1] and maxint [12, 19, 9, 0, 15, 0, 0, 3, 1, 0] detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etienne/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "--- Evolve in 332800 possible combinations ---\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=150, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500, score=-0.760687794984, total=   1.8s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.630840626565, total=   3.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500, score=-0.736751866991, total=   1.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500, score=-0.719757283889, total=   1.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=130, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=150, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.614742408452, total=   6.2s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=150, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.614500083481, total=   3.3s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=130, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.608155586898, total=   4.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=130, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.645630897132, total=   3.4s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=150, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.598035922248, total=   6.0s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=150, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.60785684407, total=   3.1s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=130, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.586728769933, total=   4.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=130, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.584853619456, total=   3.2s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=150, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.627253356232, total=   6.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=130, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.617226529296, total=   4.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.610854210588, total=   3.2s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.610381066497, total=   3.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.585639150112, total=   3.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.614728028699, total=   5.2s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.616655416719, total=   3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=90, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.594493160094, total=   5.0s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.605006430282, total=  12.3s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=90, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.648834276183, total=   3.2s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=90, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=90, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.640472516182, total=   3.0s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=90, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.624071303448, total=   4.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=90, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.656796794083, total=   3.1s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.97, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.624127789153, total=   6.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.581622105122, total=  12.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.97, objective=multi:softprob, max_depth=500, score=-0.615196064461, total=   6.3s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.97, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.601450782725, total=   7.2s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.97, objective=multi:softprob, max_depth=500, score=-0.595980269692, total=   6.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.97, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.609302159025, total=  12.2s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.97, objective=multi:softprob, max_depth=500, score=-0.624320017989, total=   6.3s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.624821278832, total=   7.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.61243810018, total=   3.4s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.611833804906, total=   2.8s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.612170557788, total=   5.2s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.589411048493, total=   2.9s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.591682218512, total=   3.5s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.61533773399, total=   2.8s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.591842320079, total=   5.3s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.621501232379, total=   3.4s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=150, subsample=0.97, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.654042626479, total=   2.8s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=150, subsample=0.97, objective=multi:softprob, max_depth=500, score=-0.611405678059, total=   4.5s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=150, subsample=0.97, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.63416440491, total=   2.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.617430025766, total=   5.5s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.660976279028, total=   2.7s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.614262152613, total=   4.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=150, subsample=0.97, objective=multi:softprob, max_depth=500, score=-0.590766333234, total=   4.5s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=150, subsample=0.97, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.610495865205, total=   5.0s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.588218375421, total=   4.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=150, subsample=0.97, objective=multi:softprob, max_depth=500, score=-0.620552447501, total=   4.6s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=50, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=50, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.630744480595, total=   1.5s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=50, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=50, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.608929941041, total=   1.6s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=50, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=190, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.620030409295, total=   4.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.58387927867, total=   5.2s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=50, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.639950077526, total=   1.7s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.61334176352, total=   1.6s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.605310387074, total=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.610073276394, total=   5.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.626936111468, total=   1.6s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=110, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.617967394923, total=   6.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=110, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.612334606157, total=   3.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=110, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.591247885081, total=   6.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=110, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.58935944192, total=   3.7s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=110, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=110, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.616155969989, total=   3.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.635443281026, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.617379223076, total=   6.4s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.608048396738, total=   2.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.583738761085, total=   2.7s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.611257765286, total=   3.0s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=90, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.607494372065, total=   7.4s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=90, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.616454922474, total=   3.1s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=90, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.610060743957, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=90, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.595559357723, total=   3.1s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=90, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.584730205145, total=   7.3s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=90, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.625164127694, total=   3.2s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500, score=-0.610889483845, total=   2.0s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500, score=-0.5913153761, total=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=50, subsample=0.95, objective=multi:softprob, max_depth=500, score=-0.61660942587, total=   2.0s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.614464003613, total=   7.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=70, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=70, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.636319849226, total=   2.1s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=70, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.636325991178, total=  12.3s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=70, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.618526698003, total=   2.1s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=70, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.619223157623, total=   6.2s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=70, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.649269517906, total=   2.1s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.612311280526, total=   2.9s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.607664203116, total=   9.0s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.591288484585, total=   2.9s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.590600997875, total=   6.1s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.620399149701, total=   3.0s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.619903140505, total=   5.8s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=130, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.587597748272, total=   8.9s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=130, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.647970007254, total=   3.2s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=130, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.611533873603, total=   6.8s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=130, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.631558729464, total=   3.0s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=130, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=130, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.656784469789, total=   3.0s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.589926065076, total=   6.7s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.61706058268, total=   9.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=90, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=90, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.62109493369, total=   4.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=90, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.619189451817, total=   7.0s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=110, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=90, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.593776324703, total=   4.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=90, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.613680049854, total=  10.6s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=110, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.609122099106, total=   3.1s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=110, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=110, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.584638447078, total=   3.0s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=110, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=90, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.617912776434, total=   4.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.618509162276, total=   1.8s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=110, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.61618292846, total=   3.0s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.592482881193, total=   2.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.624801219798, total=   1.8s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.590207058299, total=  10.6s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.609241662791, total=   5.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.612355321976, total=   4.6s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.584405688088, total=   5.3s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.586737449098, total=   4.4s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.614501902545, total=  10.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.614249542029, total=   5.5s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=190, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=130, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.615994373589, total=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.609987294433, total=   5.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.60782600012, total=   6.0s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=190, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.613825328707, total=   9.4s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=190, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.584723895749, total=   5.8s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.586161097744, total=   6.1s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.616531388876, total=   5.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=190, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.591438147998, total=   9.2s\n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=170, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.614481240211, total=   6.1s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=190, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.609769068716, total=   3.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.657190853171, total=   2.8s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.583855626545, total=   3.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.635534966164, total=   2.8s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.613897050856, total=   3.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.29, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=90, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.673632845413, total=   2.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=190, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.619345461255, total=   9.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.631114349901, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.605635932468, total=  11.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.60463082738, total=  11.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.58213160404, total=  11.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.608677922347, total=  11.0s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.631135563812, total=  11.9s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=110, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=110, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.624298984488, total=   2.6s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=110, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=110, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.605649606597, total=   2.5s\n",
      "[CV] reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=110, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=12.5437654643, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=110, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.631862201184, total=   2.6s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=190, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.608505917996, total=   4.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=190, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.616413914472, total=   3.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=190, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.581839711372, total=   4.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=190, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.594760859332, total=   3.3s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=190, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=190, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.625108390541, total=   3.3s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.613664013448, total=   4.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "gen\tnevals\tavg      \tmin     \tmax      \tstd      \n",
      "0  \t50    \t-0.614949\t-0.73907\t-0.598072\t0.0223774\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=110, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=110, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.610738063526, total=   2.9s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=110, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.608443974384, total=   3.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=110, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.587689870163, total=   2.9s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=110, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.583362861529, total=   3.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=110, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.617243081034, total=   3.0s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.616172204078, total=   3.6s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.605142795891, total=  11.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.606368820342, total=   5.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.605006430282, total=  12.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.583430180772, total=   5.3s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.581656710624, total=  11.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.611867261494, total=   5.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.581622105122, total=  12.3s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.61095124266, total=  11.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.610518320429, total=   9.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.625430625407, total=   2.1s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.604261269736, total=   2.0s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.637265991914, total=   2.0s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.609302159025, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.584639229164, total=   9.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.607743496811, total=   7.3s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.584244080225, total=   7.1s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=230, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.614764189948, total=   9.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604999689433, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.614902394148, total=   7.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.581201296859, total=   9.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.606200810141, total=  15.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.609014334111, total=   9.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.611310937394, total=  16.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.610916032239, total=   6.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.582267639241, total=  15.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.589284257491, total=   6.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.618527942012, total=   6.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.584974051542, total=  16.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.610723025733, total=  15.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.632589332701, total=   2.2s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.605746367257, total=  10.0s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.611315321393, total=   2.3s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=70, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.630944822158, total=   2.2s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=230, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.612977900923, total=  16.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.581389426784, total=  10.0s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=230, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.616509719085, total=   7.8s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=230, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.604326992483, total=  12.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.610427104118, total=   9.8s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=230, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.590620405204, total=   7.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=230, subsample=0.99, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=230, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.622133534983, total=   7.8s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.605837545609, total=   8.9s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.581233570303, total=  12.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.606877120412, total=   5.3s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.583524943843, total=   8.8s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.586366472577, total=   5.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=110, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.611638186535, total=   5.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.610229923393, total=  12.6s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.612447589246, total=   8.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.608048396738, total=   2.8s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.583738761085, total=   2.7s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.605061853988, total=  10.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.613680049854, total=  10.9s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.611257765286, total=   2.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.58271974114, total=  10.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.590207058299, total=  10.8s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.605246948967, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.608166080426, total=  11.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=230, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.614501902545, total=  10.6s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=70, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=70, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.616688988483, total=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=70, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=70, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.594701559041, total=   1.9s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=70, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.582342780757, total=  13.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=70, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.624336075175, total=   1.9s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.607811569788, total=   7.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.618684321937, total=   8.5s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.586266051453, total=   8.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.610431342743, total=  13.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.589998402493, total=   8.2s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.615880983556, total=   7.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.617253149263, total=   8.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.605098631475, total=  13.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.614912470209, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.626664108239, total=   7.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.582440872231, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.600375032788, total=   7.8s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.590864873195, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.626736635959, total=   7.7s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608263738906, total=  11.8s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.617663242753, total=  10.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.615498395613, total=   5.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.589439053958, total=   5.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.3, colsample_bylevel=0.45, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.615059993308, total=   5.0s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "1  \t29    \t-0.603377\t-0.624951\t-0.598072\t0.00601587\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.603868880982, total=   8.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.626449519678, total=   9.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.581973646389, total=   8.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.595279189701, total=   9.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.608851062605, total=   8.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.627696517608, total=   9.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.1s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.607744151516, total=   9.1s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.605540826245, total=  13.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.610495865205, total=   4.9s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.584021102604, total=   9.2s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.58387927867, total=   5.0s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=170, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.610073276394, total=   4.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.58155592352, total=  13.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.612816750499, total=   9.2s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.605098631475, total=  12.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.605728645872, total=   9.3s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.611280441671, total=  14.0s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.581810914605, total=   9.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.582440872231, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.605142795891, total=  11.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.611626445495, total=   9.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.748455771452, total=   1.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.737224495819, total=   1.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.74706245311, total=   1.6s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.581656710624, total=  11.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.39, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608263738906, total=  13.0s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.65296843317, total=   2.8s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.630927562712, total=   2.9s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.662681401858, total=   2.9s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=270, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.61095124266, total=  11.5s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.606108306238, total=  13.2s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.609492008574, total=   3.6s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.84, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=270, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.61588536981, total=   9.2s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=270, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.587021864194, total=   3.6s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.84, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=70, subsample=0.84, objective=multi:softprob, max_depth=500, score=-0.613143169004, total=   3.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.583554299548, total=  13.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=270, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.591025828423, total=   9.2s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=270, subsample=0.98, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.604273214024, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=270, subsample=0.98, objective=multi:softprob, max_depth=500, score=-0.616021385483, total=   8.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.609809802692, total=  13.0s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.605578754851, total=   5.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.581045176063, total=  10.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.584128137693, total=   5.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.605006430282, total=  12.4s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.608871165296, total=   9.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.2, colsample_bylevel=0.45, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.612653510619, total=   5.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  13.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.581622105122, total=  15.2s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.606039687141, total=  16.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.609302159025, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.582292077242, total=  14.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604999689433, total=   9.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.581201296859, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.611322664928, total=  14.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.609014334111, total=   9.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.606954732443, total=   6.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=110, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.584418464398, total=   6.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=110, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.605261754042, total=   5.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=110, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.41, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.612416693965, total=   6.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=110, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.587907153473, total=   5.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=110, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=110, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.614109550792, total=   5.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.604017549968, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.652545603144, total=   3.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.623563314333, total=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.606200810141, total=  15.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=70, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.651768077232, total=   3.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.582074644056, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.608679549477, total=   9.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.582267639241, total=  15.6s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.608821843487, total=  14.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.610723025733, total=  15.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.9s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.584343927603, total=  14.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.610024671797, total=  11.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  11.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.605635932468, total=   9.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  10.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.58213160404, total=   9.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604999689433, total=   8.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.45, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.608677922347, total=   9.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.581201296859, total=   8.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.609014334111, total=   8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608098535575, total=  10.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580796186996, total=  10.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.53, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.610278395704, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "2  \t39    \t-0.604362\t-0.744248\t-0.59696 \t0.0221422 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604999689433, total=   9.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  11.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.581201296859, total=   9.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  11.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.609014334111, total=   9.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  11.8s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.3s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.605179440623, total=  11.8s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.604865479011, total=  11.8s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.581327423761, total=  11.8s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.580252114122, total=  11.9s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.610797295121, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.82, objective=multi:softprob, max_depth=500, score=-0.606330919789, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.602855830114, total=  10.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604202241504, total=  11.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.583142327572, total=  10.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580493498266, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.606664756841, total=   9.9s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608735703807, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604377443105, total=  12.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.60338333209, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.579959577081, total=  12.9s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580088170421, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.610035659972, total=  12.7s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607942610733, total=  12.6s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=190, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=190, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.620975346153, total=   6.4s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=190, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.605664559714, total=   8.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=190, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.601111971532, total=   6.4s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=190, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  11.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.581436070216, total=   8.5s\n",
      "[CV] reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.96, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=190, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.630412863576, total=   6.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=5.12992784003, n_jobs=2, colsample_bytree=0.49, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=210, subsample=0.96, objective=multi:softprob, max_depth=500, score=-0.611596144868, total=   8.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.603715265733, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.580122825207, total=   9.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.608499615786, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.605649365682, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.581151145288, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.60338333209, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.60728031743, total=  12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580088170421, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604202241504, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580493498266, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607942610733, total=  13.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604999689433, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608735703807, total=  11.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.581201296859, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  13.5s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  15.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.609014334111, total=  10.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.61587028608, total=   6.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.589777168865, total=   6.3s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.604273214024, total=   9.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.33, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=210, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.618836175466, total=   6.8s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.581045176063, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  14.8s\n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.609463903312, total=  12.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.93, objective=multi:softprob, max_depth=500, score=-0.608871165296, total=   8.8s\n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.586495125966, total=  10.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=270, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.613098683257, total=  10.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "3  \t35    \t-0.598658\t-0.6175  \t-0.59696 \t0.00315828\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  19.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  20.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.608076943075, total=  20.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  13.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.582828076902, total=  14.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  13.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.609478710783, total=  14.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.605649365682, total=  13.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.581151145288, total=  15.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.92, objective=multi:softprob, max_depth=500, score=-0.60728031743, total=  14.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  13.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.623979720108, total=  12.1s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.605883791837, total=  13.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.596184371663, total=  16.1s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  19.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.581196229489, total=  16.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.625672744562, total=  22.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.89, objective=multi:softprob, max_depth=500, score=-0.607145636731, total=  21.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  26.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  26.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.602855830114, total=  21.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.60481919126, total=  27.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.583142327572, total=  18.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  27.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580763738055, total=  29.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.606664756841, total=  18.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  24.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608630194456, total=  25.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  25.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.603715265733, total=  19.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  24.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  22.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.580122825207, total=  19.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  17.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  16.8s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.91, objective=multi:softprob, max_depth=500, score=-0.608499615786, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  10.0s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=   9.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=   9.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=   9.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "4  \t17    \t-0.597754\t-0.61528 \t-0.596712\t0.00256939\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.61272206037, total=   6.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  11.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.591546417453, total=   6.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.616934339446, total=   6.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.614542880612, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  11.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.587241389431, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.606839830609, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.614979858772, total=  12.1s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.580877681254, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607645481077, total=   7.8s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.587763297018, total=   8.0s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.608530427281, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.614163647536, total=   9.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.621250599853, total=   9.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.597445083298, total=   9.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.608076943075, total=  18.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.62336271426, total=   7.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.582828076902, total=  17.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  13.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.35, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  14.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.47, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.609478710783, total=  15.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603150347824, total=  10.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  13.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.583922382415, total=  10.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.611864897787, total=   8.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.603277180026, total=  14.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.6026906555, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.581244977997, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  14.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.582543179448, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.85, objective=multi:softprob, max_depth=500, score=-0.607239854301, total=  13.1s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  15.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.606703473222, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.604275076727, total=  12.4s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.602855830114, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.58061175369, total=  12.2s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.583142327572, total=  11.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.607884109913, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.606134010433, total=   9.1s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.86, objective=multi:softprob, max_depth=500, score=-0.606664756841, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.6936345109, total=   2.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.676597933151, total=   2.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.583027810213, total=   9.0s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=50, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.698619830385, total=   2.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.61097815714, total=   9.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  13.8s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  10.5s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=   9.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=   9.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=   9.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=   9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "5  \t27    \t-0.599898\t-0.689618\t-0.596712\t0.0131848 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.608056352829, total=   5.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.582247713607, total=   5.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.25, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=150, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.610931742614, total=   5.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  15.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  13.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  13.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.5s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.606221680721, total=   9.6s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.584613251715, total=   9.0s\n",
      "[CV] reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=4.28990744493, n_jobs=2, colsample_bytree=0.31, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.612552069709, total=   9.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.61730120562, total=   2.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.597744387301, total=   2.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=50, subsample=0.99, objective=multi:softprob, max_depth=500, score=-0.624039406718, total=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.6s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.614342829885, total=   7.2s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.594353009756, total=   6.9s\n",
      "[CV] reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=8.77205321464, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.624885430005, total=   7.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.1s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  10.2s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  10.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "6  \t30    \t-0.597614\t-0.613028\t-0.596712\t0.00306583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.618524143919, total=  10.0s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.593301524307, total=  10.0s\n",
      "[CV] reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.5874395235, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.62012611657, total=  10.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.604202241504, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.580493498266, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.3s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.608735703807, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.616114957712, total=   7.7s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.596701665239, total=   7.6s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.603065679483, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.625930163138, total=   8.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.580115556739, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.87, objective=multi:softprob, max_depth=500, score=-0.607697165187, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.608744260759, total=   6.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.587644484214, total=   7.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  14.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.616718254667, total=   8.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  22.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  23.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  23.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  24.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  24.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  27.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  26.0s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  24.9s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  24.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  13.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "7  \t37    \t-0.597505\t-0.612915\t-0.596712\t0.00311584\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  21.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  22.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  22.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  16.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  15.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  15.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.6s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.604883791628, total=   9.4s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.582198124975, total=   9.7s\n",
      "[CV] reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=6.13443529534, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.613215627631, total=   9.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.605297612832, total=   8.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.583528594441, total=   8.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.610188889115, total=   8.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.605297612832, total=   9.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.583528594441, total=   8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.2s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.610188889115, total=   8.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=   9.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  10.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  10.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  10.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  10.2s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.604186334401, total=  10.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.57953199604, total=  10.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=270, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.607151919366, total=  10.8s\n",
      "8  \t24    \t-0.596903\t-0.600099\t-0.596712\t0.000737909\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.616707986043, total=  15.6s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  23.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  24.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.597262786758, total=  15.0s\n",
      "[CV] reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=15.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.88, objective=multi:softprob, max_depth=500, score=-0.626701921401, total=  15.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  22.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  23.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  22.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  22.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  23.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.606839830609, total=  20.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  22.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.63613323697, total=  21.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.580877681254, total=  23.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  22.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.608368216306, total=  22.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.608744260759, total=  12.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.4, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.632421343496, total=  18.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.81, objective=multi:softprob, max_depth=500, score=-0.608530427281, total=  22.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.587644484214, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=130, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.616718254667, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=290, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  18.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  18.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  11.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=290, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.605396074519, total=  13.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=290, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=290, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579764211521, total=  14.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=290, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  13.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.614542880612, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=290, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.607429843326, total=  13.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  14.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.587241389431, total=  17.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  18.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  16.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.2, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.614979858772, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  14.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  16.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  16.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  20.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  18.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  19.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  18.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  16.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  14.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.608269249975, total=  16.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60959354626, total=  17.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  10.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.584975938238, total=  16.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.94, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  11.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.586621457544, total=  17.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  13.1s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.51, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.94, objective=multi:softprob, max_depth=500, score=-0.614079402948, total=  18.0s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.55, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.613529711442, total=  17.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "9  \t31    \t-0.598261\t-0.625642\t-0.596712\t0.00493675 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603423901415, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579446806498, total=  11.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=210, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.607676455243, total=  10.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.607596113346, total=   9.1s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.583884006424, total=   9.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.27, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.61058362921, total=  10.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.624479557711, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  13.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.605297612832, total=   8.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.583528594441, total=   8.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.598226259501, total=  11.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.610188889115, total=   8.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.3, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.625461040494, total=  12.2s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.605191669435, total=  12.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.610936332599, total=  10.4s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  17.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.589849387692, total=  14.1s\n",
      "[CV] reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.580975674674, total=  17.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.83, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=10.4897368015, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.619778351357, total=   9.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  13.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.83, objective=multi:softprob, max_depth=500, score=-0.609180552636, total=  11.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  14.4s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  13.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  14.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  17.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  16.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  17.9s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.6s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  11.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.605297612832, total=   8.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.605537038248, total=  10.4s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  12.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.583528594441, total=   8.6s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.581972323319, total=  10.0s\n",
      "[CV] reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.45, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.610188889115, total=   8.3s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=  12.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=7.33563854429, n_jobs=2, colsample_bytree=0.43, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.612163989878, total=  10.0s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  11.2s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=  12.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.603869265145, total=  10.7s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=   9.8s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.579349181859, total=   9.5s\n",
      "[CV] reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500 \n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=   9.6s\n",
      "[CV]  reg_alpha=3.0, n_jobs=2, colsample_bytree=0.37, missing=nan, learning_rate=0.1, colsample_bylevel=0.65, n_estimators=250, subsample=0.9, objective=multi:softprob, max_depth=500, score=-0.60691689963, total=   9.4s\n",
      "10 \t34    \t-0.597601\t-0.616056\t-0.596712\t0.0031114  \n",
      "Best individual is: {'reg_alpha': 3.0, 'n_jobs': 2, 'colsample_bytree': 0.37000000000000011, 'missing': nan, 'learning_rate': 0.10000000000000001, 'colsample_bylevel': 0.65000000000000002, 'n_estimators': 250, 'subsample': 0.90000000000000013, 'objective': 'multi:softprob', 'max_depth': 500}\n",
      "with fitness: -0.59671238442\n",
      "  -0.59671238442\n",
      "  {'reg_alpha': 3.0, 'n_jobs': 2, 'colsample_bytree': 0.37000000000000011, 'missing': nan, 'learning_rate': 0.10000000000000001, 'colsample_bylevel': 0.65000000000000002, 'n_estimators': 250, 'subsample': 0.90000000000000013, 'objective': 'multi:softprob', 'max_depth': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "# We use the genetic algorithm cross validation search library at https://github.com/rsteca/sklearn-deap \n",
    "# in order to optimize the XGBoost Hyperparameters.\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "\n",
    "# Ideally we use approx. 10 folds\n",
    "k_fold = 3\n",
    "  \n",
    "# Use Stratified KFold so as to mitigate the effects of the imbalanced dataset.\n",
    "# Stratified k-fold makes sure that the cross validation folds are always selected with the same \n",
    "# ratio of outcome classes\n",
    "cv = StratifiedKFold(y_train[:,0],n_folds=k_fold,shuffle=True)\n",
    "  \n",
    "# initialize the classifier\n",
    "GB = xgb.XGBClassifier()\n",
    "  \n",
    "# Define the hyperparamer ranges inside which we want to optimize our model\n",
    "param_grid = {'max_depth': [500],\n",
    "              'learning_rate': np.arange(0.1,0.5, 0.1),\n",
    "              'objective':['multi:softprob'],\n",
    "              'n_jobs': [2],\n",
    "              'missing': [np.nan],\n",
    "              'reg_alpha': np.geomspace(3, 15, 10, endpoint=True),\n",
    "              'colsample_bytree': np.arange(0.25, 0.55, 0.02),\n",
    "              'colsample_bylevel': np.arange(0.45, 0.85, 0.2),\n",
    "              'subsample': np.arange(0.80, 1, 0.01),\n",
    "              'n_estimators': np.arange(50, 300, 20)}\n",
    "\n",
    "search_GB = EvolutionaryAlgorithmSearchCV(estimator=GB,\n",
    "                                   params=param_grid,\n",
    "                                   scoring=\"neg_log_loss\",\n",
    "                                   cv=cv,\n",
    "                                   verbose=10,\n",
    "                                   population_size=50,\n",
    "                                   gene_mutation_prob=0.20,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=5,\n",
    "                                   generations_number=10,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "search_GB.fit(X_train,y_train[:,0])\n",
    "print ' ',search_GB.best_score_\n",
    "print ' ',search_GB.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.59671238442\n",
      "{'reg_alpha': 3.0, 'n_jobs': 2, 'colsample_bytree': 0.37000000000000011, 'missing': nan, 'learning_rate': 0.10000000000000001, 'colsample_bylevel': 0.65000000000000002, 'n_estimators': 250, 'subsample': 0.90000000000000013, 'objective': 'multi:softprob', 'max_depth': 500}\n"
     ]
    }
   ],
   "source": [
    "print search_GB.best_score_\n",
    "print search_GB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 0 ..., 3 0 0]\n",
      "[[  9.58674967e-01   5.85305970e-04   4.23185877e-04   6.13932917e-03\n",
      "    3.41772363e-02]\n",
      " [  2.70544618e-01   4.30020358e-04   1.14835426e-03   4.22662705e-01\n",
      "    3.05214316e-01]\n",
      " [  8.43968332e-01   9.84159997e-04   1.06107292e-03   1.66635457e-02\n",
      "    1.37322858e-01]\n",
      " ..., \n",
      " [  2.04300001e-01   6.66413165e-04   1.32813421e-03   6.23684049e-01\n",
      "    1.70021385e-01]\n",
      " [  8.84840548e-01   5.61470166e-04   5.62571571e-04   4.46258392e-03\n",
      "    1.09572776e-01]\n",
      " [  9.40782309e-01   3.28272727e-04   2.43720555e-04   2.05013808e-02\n",
      "    3.81442830e-02]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#params={'reg_alpha': 31.6227766, 'n_jobs': 2, 'colsample_bytree': 0.92004019236052659, 'missing': nan, 'learning_rate': 0.45372879619918061, 'n_estimators': 172, 'subsample': 0.4933391563450169, 'objective': 'multi:softprob', 'max_depth': 43}\n",
    "#params={'reg_alpha': 5.62341325, 'n_jobs': 2, 'colsample_bytree': 0.52605500347528933, 'missing': nan, 'learning_rate': 0.064258457713594841, 'n_estimators': 140, 'subsample': 0.98851834712965414, 'objective': 'multi:softprob', 'max_depth': 8}\n",
    "#params={'reg_alpha': 0.26826957952797248, 'n_jobs': 2, 'colsample_bytree': 0.48923015934746311, 'missing': nan, 'learning_rate': 0.6550359822797861, 'n_estimators': 67, 'subsample': 0.97882979580504648, 'objective': 'multi:softprob', 'max_depth': 74}\n",
    "#params={'reg_alpha': 13.894954943731374, 'n_jobs': 2, 'colsample_bytree': 0.42988412779163959, 'missing': nan, 'learning_rate': 0.8455569183464563, 'n_estimators': 130, 'subsample': 0.75090906210651975, 'objective': 'multi:softprob', 'max_depth': 200}\n",
    "params={'reg_alpha': 2.21221629107, 'n_jobs':2, 'colsample_bytree':0.3, 'missing':nan, 'learning_rate':0.1, 'colsample_bylevel':0.7, 'n_estimators':300, 'subsample':0.8, 'objective':'multi:softprob', 'max_depth':500}\n",
    "GB = xgb.XGBClassifier(**search_GB.best_params_)\n",
    "\n",
    "GB.fit(X_train, y_train[:,0])\n",
    "\n",
    "prepreds = preclf.predict(X_test)\n",
    "prepreds = np.reshape(prepreds, (len(prepreds), 1))\n",
    "#print prepreds\n",
    "#print X_test_pre_red.shape\n",
    "preds = GB.predict(np.hstack((X_test, prepreds)))##X_test)\n",
    "proba = GB.predict_proba(np.hstack((X_test, prepreds)))#X_test)\n",
    "\n",
    "#preds = GB.predict(X_test[:,final_support])#X_test)\n",
    "\n",
    "#proba = GB.predict_proba(X_test[:,final_support])#X_test)\n",
    "\n",
    "\n",
    "print preds\n",
    "print proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score= 0.674897119342\n",
      "log loss= 0.99070442305\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "f1score = f1_score(y_test, preds, average=\"micro\")\n",
    "logloss = log_loss(y_test, proba, labels=GB.classes_)\n",
    "print \"f1 score=\", f1score\n",
    "print \"log loss=\", logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAJcCAYAAACixjPMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f580b4210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_bin = label_binarize(y_test[:,0], GB.classes_)\n",
    "plotROCCurves(GB.classes_, labelMapper.features[0][1].inverse_transform(GB.classes_), y_test_bin, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n",
      "2521\n",
      "2154\n",
      "2521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1771,    0,    0,  217,  166],\n",
       "       [   6,    0,    0,    3,   30],\n",
       "       [  52,    0,    6,   61,  192],\n",
       "       [ 359,    0,    4,  467,  127],\n",
       "       [ 333,    0,    3,  185, 1364]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print labelMapper.features[0][1].inverse_transform(GB.classes_)\n",
    "cm = confusion_matrix(y_test[:,0], preds)#y_train[:,0]\n",
    "print np.sum(preds==0)\n",
    "print np.sum(y_test[:,0]==0)\n",
    "print sum(cm[:,0])\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitSex...\n",
      "cleanupBreed...\n",
      "processBreed...\n",
      "(26729, 262)\n",
      "processAge...\n",
      "processDate...\n",
      "processWeekend...\n",
      "processName...\n",
      "processColor...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=0.65000000000000002,\n",
       "       colsample_bytree=0.37000000000000011, gamma=0,\n",
       "       learning_rate=0.10000000000000001, max_delta_step=0, max_depth=500,\n",
       "       min_child_weight=1, missing=None, n_estimators=250, n_jobs=2,\n",
       "       nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=3.0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.90000000000000013)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full, y_full = prepareDFForPrediction(df, df[[\"OutcomeType\"]])\n",
    "preclf.fit(X_full.values[:,final_support[:-1]], y_full.values.ravel())\n",
    "\n",
    "y_full_simple=getSimpleOutcome(y_full.values)\n",
    "     \n",
    "GB.fit(np.hstack((X_full.values, np.array(y_full_simple)[np.newaxis].T))[:,final_support], y_full.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitSex...\n",
      "cleanupBreed...\n",
      "processBreed...\n",
      "(11456, 262)\n",
      "processAge...\n",
      "processDate...\n",
      "processWeekend...\n",
      "processName...\n",
      "processColor...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Neutered</th>\n",
       "      <th>PureBreed</th>\n",
       "      <th>AgeBracket_adult</th>\n",
       "      <th>AgeBracket_baby</th>\n",
       "      <th>AgeBracket_juvenile</th>\n",
       "      <th>DaySegment_HR_0</th>\n",
       "      <th>DaySegment_HR_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Breed_whippet</th>\n",
       "      <th>Breed_wire</th>\n",
       "      <th>Breed_wirehair</th>\n",
       "      <th>Breed_wirehaired</th>\n",
       "      <th>Breed_wolfhound</th>\n",
       "      <th>Breed_yorkshire</th>\n",
       "      <th>AgeDays</th>\n",
       "      <th>OutcomeDay</th>\n",
       "      <th>OutcomeMonth</th>\n",
       "      <th>OutcomeHour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AnimalType  Sex_female  Sex_male  Neutered  PureBreed  AgeBracket_adult  \\\n",
       "0           1           1         0         0          0                 0   \n",
       "1           1           1         0         1          0                 1   \n",
       "2           0           0         1         1          0                 0   \n",
       "3           1           0         1         0          0                 0   \n",
       "4           1           0         1         1          0                 1   \n",
       "\n",
       "   AgeBracket_baby  AgeBracket_juvenile  DaySegment_HR_0  DaySegment_HR_1  \\\n",
       "0                0                    1                0                0   \n",
       "1                0                    0                0                0   \n",
       "2                0                    1                0                0   \n",
       "3                0                    1                0                0   \n",
       "4                0                    0                0                0   \n",
       "\n",
       "      ...       Breed_whippet  Breed_wire  Breed_wirehair  Breed_wirehaired  \\\n",
       "0     ...                   0           0               0                 0   \n",
       "1     ...                   0           0               0                 0   \n",
       "2     ...                   0           0               0                 0   \n",
       "3     ...                   0           0               0                 0   \n",
       "4     ...                   0           0               0                 0   \n",
       "\n",
       "   Breed_wolfhound  Breed_yorkshire  AgeDays  OutcomeDay  OutcomeMonth  \\\n",
       "0                0                0    300.0          12            10   \n",
       "1                0                0    730.0          26             7   \n",
       "2                0                0    365.0          13             1   \n",
       "3                0                0    120.0          28            12   \n",
       "4                0                0    730.0          24             9   \n",
       "\n",
       "   OutcomeHour  \n",
       "0           12  \n",
       "1           17  \n",
       "2           12  \n",
       "3           18  \n",
       "4           17  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.read_csv(\"test.csv\")\n",
    "\n",
    "testdf, y = prepareDFForPrediction(testdf)\n",
    "\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26729, 284)\n",
      "(11456, 15)\n",
      "[0 1 2 3 4]\n",
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.112610</td>\n",
       "      <td>0.855034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.033279</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.898497</td>\n",
       "      <td>0.013922</td>\n",
       "      <td>0.003924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>0.053277</td>\n",
       "      <td>0.914328</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.090163</td>\n",
       "      <td>0.868781</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>0.011423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.031199</td>\n",
       "      <td>0.934108</td>\n",
       "      <td>0.014675</td>\n",
       "      <td>0.003863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.225406</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.593531</td>\n",
       "      <td>0.179676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.533888</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.214565</td>\n",
       "      <td>0.243885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.861098</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.126306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.064058</td>\n",
       "      <td>0.108227</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>0.029702</td>\n",
       "      <td>0.012212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.026580</td>\n",
       "      <td>0.939097</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.049151</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.874257</td>\n",
       "      <td>0.017869</td>\n",
       "      <td>0.004206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.031927</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.233175</td>\n",
       "      <td>0.733757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.048284</td>\n",
       "      <td>0.064490</td>\n",
       "      <td>0.856815</td>\n",
       "      <td>0.011942</td>\n",
       "      <td>0.018469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.904868</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.005572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.894241</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.002086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.046706</td>\n",
       "      <td>0.080133</td>\n",
       "      <td>0.838520</td>\n",
       "      <td>0.028281</td>\n",
       "      <td>0.006360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.018311</td>\n",
       "      <td>0.958808</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0.003193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.386224</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.571235</td>\n",
       "      <td>0.041715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.274089</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.144078</td>\n",
       "      <td>0.580526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>0.964656</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.010350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.033034</td>\n",
       "      <td>0.937215</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.006822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.997153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.021996</td>\n",
       "      <td>0.031898</td>\n",
       "      <td>0.930712</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.006014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.996633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.033177</td>\n",
       "      <td>0.049168</td>\n",
       "      <td>0.899649</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.934708</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.015534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.101546</td>\n",
       "      <td>0.124717</td>\n",
       "      <td>0.759648</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.008916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.177737</td>\n",
       "      <td>0.810653</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.007574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.017825</td>\n",
       "      <td>0.961261</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.003751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.022577</td>\n",
       "      <td>0.952227</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>11427</td>\n",
       "      <td>0.451495</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.367465</td>\n",
       "      <td>0.179918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>11428</td>\n",
       "      <td>0.244311</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.075098</td>\n",
       "      <td>0.679236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>11429</td>\n",
       "      <td>0.134285</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.425963</td>\n",
       "      <td>0.438728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>11430</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.037993</td>\n",
       "      <td>0.919436</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.002665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>11431</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.155035</td>\n",
       "      <td>0.767487</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.012271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11431</th>\n",
       "      <td>11432</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.995504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11432</th>\n",
       "      <td>11433</td>\n",
       "      <td>0.352265</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.535496</td>\n",
       "      <td>0.111328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11433</th>\n",
       "      <td>11434</td>\n",
       "      <td>0.037811</td>\n",
       "      <td>0.338842</td>\n",
       "      <td>0.610916</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.009842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11434</th>\n",
       "      <td>11435</td>\n",
       "      <td>0.504703</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.344924</td>\n",
       "      <td>0.149337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11435</th>\n",
       "      <td>11436</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.994219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11436</th>\n",
       "      <td>11437</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>0.065443</td>\n",
       "      <td>0.893243</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.004884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11437</th>\n",
       "      <td>11438</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.037921</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.011584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438</th>\n",
       "      <td>11439</td>\n",
       "      <td>0.101816</td>\n",
       "      <td>0.203883</td>\n",
       "      <td>0.685130</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.006658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11439</th>\n",
       "      <td>11440</td>\n",
       "      <td>0.024723</td>\n",
       "      <td>0.048187</td>\n",
       "      <td>0.910649</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.005833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11440</th>\n",
       "      <td>11441</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.996415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11441</th>\n",
       "      <td>11442</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.020012</td>\n",
       "      <td>0.953202</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>0.003924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11442</th>\n",
       "      <td>11443</td>\n",
       "      <td>0.023029</td>\n",
       "      <td>0.033256</td>\n",
       "      <td>0.928808</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>0.004609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11443</th>\n",
       "      <td>11444</td>\n",
       "      <td>0.729758</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.029387</td>\n",
       "      <td>0.240133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11444</th>\n",
       "      <td>11445</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.068215</td>\n",
       "      <td>0.923148</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.006355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11445</th>\n",
       "      <td>11446</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.997555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11446</th>\n",
       "      <td>11447</td>\n",
       "      <td>0.153475</td>\n",
       "      <td>0.123321</td>\n",
       "      <td>0.716140</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11447</th>\n",
       "      <td>11448</td>\n",
       "      <td>0.034402</td>\n",
       "      <td>0.052870</td>\n",
       "      <td>0.896041</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.007379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>11449</td>\n",
       "      <td>0.132878</td>\n",
       "      <td>0.136814</td>\n",
       "      <td>0.718542</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.007669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>11450</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.908893</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.020241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>11451</td>\n",
       "      <td>0.017567</td>\n",
       "      <td>0.027462</td>\n",
       "      <td>0.928147</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.007481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>11452</td>\n",
       "      <td>0.602855</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.385058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>11453</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.995520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11453</th>\n",
       "      <td>11454</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.995740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11454</th>\n",
       "      <td>11455</td>\n",
       "      <td>0.486949</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.438948</td>\n",
       "      <td>0.073248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11455</th>\n",
       "      <td>11456</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.025885</td>\n",
       "      <td>0.954775</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>0.003792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11456 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Adoption      Died  Euthanasia  Return_to_owner  Transfer\n",
       "0          1  0.031514  0.000336    0.000506         0.112610  0.855034\n",
       "1          2  0.033279  0.050378    0.898497         0.013922  0.003924\n",
       "2          3  0.011964  0.053277    0.914328         0.009230  0.011200\n",
       "3          4  0.013225  0.090163    0.868781         0.016408  0.011423\n",
       "4          5  0.016155  0.031199    0.934108         0.014675  0.003863\n",
       "5          6  0.225406  0.000444    0.000943         0.593531  0.179676\n",
       "6          7  0.533888  0.004109    0.003552         0.214565  0.243885\n",
       "7          8  0.861098  0.000800    0.000575         0.011222  0.126306\n",
       "8          9  0.064058  0.108227    0.785801         0.029702  0.012212\n",
       "9         10  0.016948  0.026580    0.939097         0.013246  0.004130\n",
       "10        11  0.049151  0.054517    0.874257         0.017869  0.004206\n",
       "11        12  0.031927  0.000365    0.000776         0.233175  0.733757\n",
       "12        13  0.048284  0.064490    0.856815         0.011942  0.018469\n",
       "13        14  0.023126  0.062209    0.904868         0.004225  0.005572\n",
       "14        15  0.058332  0.032231    0.894241         0.013109  0.002086\n",
       "15        16  0.046706  0.080133    0.838520         0.028281  0.006360\n",
       "16        17  0.006647  0.018311    0.958808         0.013041  0.003193\n",
       "17        18  0.386224  0.000299    0.000526         0.571235  0.041715\n",
       "18        19  0.274089  0.000592    0.000715         0.144078  0.580526\n",
       "19        20  0.000410  0.023347    0.964656         0.001236  0.010350\n",
       "20        21  0.011094  0.033034    0.937215         0.011835  0.006822\n",
       "21        22  0.000555  0.000327    0.000275         0.001689  0.997153\n",
       "22        23  0.021996  0.031898    0.930712         0.009380  0.006014\n",
       "23        24  0.001365  0.000295    0.000243         0.001463  0.996633\n",
       "24        25  0.033177  0.049168    0.899649         0.011961  0.006046\n",
       "25        26  0.007163  0.039735    0.934708         0.002860  0.015534\n",
       "26        27  0.101546  0.124717    0.759648         0.005172  0.008916\n",
       "27        28  0.002911  0.177737    0.810653         0.001125  0.007574\n",
       "28        29  0.006918  0.017825    0.961261         0.010245  0.003751\n",
       "29        30  0.008388  0.022577    0.952227         0.013133  0.003675\n",
       "...      ...       ...       ...         ...              ...       ...\n",
       "11426  11427  0.451495  0.000419    0.000703         0.367465  0.179918\n",
       "11427  11428  0.244311  0.000802    0.000553         0.075098  0.679236\n",
       "11428  11429  0.134285  0.000313    0.000711         0.425963  0.438728\n",
       "11429  11430  0.017360  0.037993    0.919436         0.022546  0.002665\n",
       "11430  11431  0.061310  0.155035    0.767487         0.003896  0.012271\n",
       "11431  11432  0.001123  0.000294    0.000462         0.002616  0.995504\n",
       "11432  11433  0.352265  0.000337    0.000574         0.535496  0.111328\n",
       "11433  11434  0.037811  0.338842    0.610916         0.002589  0.009842\n",
       "11434  11435  0.504703  0.000531    0.000505         0.344924  0.149337\n",
       "11435  11436  0.002105  0.000362    0.000457         0.002857  0.994219\n",
       "11436  11437  0.032059  0.065443    0.893243         0.004372  0.004884\n",
       "11437  11438  0.002715  0.037921    0.939286         0.008494  0.011584\n",
       "11438  11439  0.101816  0.203883    0.685130         0.002513  0.006658\n",
       "11439  11440  0.024723  0.048187    0.910649         0.010608  0.005833\n",
       "11440  11441  0.001140  0.000289    0.000258         0.001898  0.996415\n",
       "11441  11442  0.008235  0.020012    0.953202         0.014628  0.003924\n",
       "11442  11443  0.023029  0.033256    0.928808         0.010299  0.004609\n",
       "11443  11444  0.729758  0.000510    0.000212         0.029387  0.240133\n",
       "11444  11445  0.001072  0.068215    0.923148         0.001209  0.006355\n",
       "11445  11446  0.000308  0.000182    0.000211         0.001744  0.997555\n",
       "11446  11447  0.153475  0.123321    0.716140         0.002998  0.004066\n",
       "11447  11448  0.034402  0.052870    0.896041         0.009308  0.007379\n",
       "11448  11449  0.132878  0.136814    0.718542         0.004097  0.007669\n",
       "11449  11450  0.024210  0.038050    0.908893         0.008606  0.020241\n",
       "11450  11451  0.017567  0.027462    0.928147         0.019342  0.007481\n",
       "11451  11452  0.602855  0.000887    0.000660         0.010540  0.385058\n",
       "11452  11453  0.000670  0.000452    0.000254         0.003103  0.995520\n",
       "11453  11454  0.001256  0.000317    0.000291         0.002396  0.995740\n",
       "11454  11455  0.486949  0.000348    0.000506         0.438948  0.073248\n",
       "11455  11456  0.002131  0.025885    0.954775         0.013416  0.003792\n",
       "\n",
       "[11456 rows x 6 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kaggle_test = testdf.loc[:, testdf.columns!=\"ID\"].values\n",
    "print X_full.shape\n",
    "print X_kaggle_test[:,final_support[:-1]].shape\n",
    "prepreds = preclf.predict(X_kaggle_test[:,final_support[:-1]])\n",
    "prepreds = np.reshape(prepreds, (len(prepreds), 1))\n",
    "\n",
    "X_kaggle_test = np.hstack((X_kaggle_test, prepreds))\n",
    "    \n",
    "preds = GB.predict(X_kaggle_test[:,final_support])\n",
    "probs = GB.predict_proba(X_kaggle_test[:,final_support])\n",
    "print GB.classes_\n",
    "print labelMapper.features[0][1].inverse_transform(GB.classes_)\n",
    "results = np.concatenate((testdf[[\"ID\"]].values, probs), axis=1)\n",
    "resultsdf = pd.DataFrame(results, columns=[\"ID\",\"Adoption\",\"Died\",\"Euthanasia\",\"Return_to_owner\",\"Transfer\"])\n",
    "resultsdf[\"ID\"] = resultsdf[\"ID\"].astype(int)\n",
    "resultsdf.to_csv(\"results3csv\", index=False)\n",
    "resultsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
